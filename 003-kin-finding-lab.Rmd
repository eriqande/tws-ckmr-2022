# Kin-finding lab

```{r libraries.etc, echo=FALSE, results='hide', message=FALSE}
cache_chunks = TRUE
```

In this session, we are going to get our hands dirty with a lovely data set
of genetic data from 1,484 bearded seals and use those data to find kin pairs
from amongst the ${1,484 \choose 2} = 1,100,386$ pairs that can be formed
from all those samples.  

This data set includes 2,569 genetic markers.  These markers were filtered down
for quality and reliability from a much larger set.  We won't talk about that
process, here, but keep in mind that a huge part of a successful CKMR project
involves getting and curating a quality set of genetic markers.

We will first estimate how much power we expect to have for identifying
kin pairs with this marker set, and then we will actually do the kin-finding.
Both of these steps will be done using the R package 'CKMRsim' that Eric wrote.
It is available from GitHub at https://github.com/eriqande/CKMRsim and its
online documentation can be read at: https://eriqande.github.io/CKMRsim/.

If you want to use 'CKMRsim' yourself in a different project, you would need
to install it like this:
```{r, eval=FALSE}
remotes::install_github("eriqande/CKMRsim")
```
However, we have already included it in the `tws-ckmr-2022` project using
'renv', so you don't have to install it now.

Before proceeding, we will load all of the libraries that we will be using
for this session.  Additionally, we will download and install the
binary of the `mendel` program so that we can simulate genetic markers with
physical linkage.
```{r inst-pkgs, message=FALSE}
library(tidyverse)
library(CKMRsim)

# the next step tests to see if mendel was already installed.
# if not, it installs it
if(system.file("bin", package = "CKMRsim") == "") {
  install_mendel(Dir = system.file(package = "CKMRsim"))
}
```

## Looking at the genetic data and pivoting it 

We load the genetic data from an RDS file:
```{r load-genos}
beardo_genos <- read_rds("data/beardo-genos.rds")
```

Here are the first 10 rows and 9 columns of that data set:
```{r cols11}
beardo_genos[1:10, 1:9]
```
The full data set has `r nrow(beardo_genos)` rows and `r ncol(beardo_genos)` columns.

This is a standard genotype format. The first column gives the sample name and
every subsequent pair of columns gives the alleles found in the sample at a
genetic marker or "locus".

These markers are single nucleotide polymorphism (SNP) markers.  These markers
are typically biallelic, and in this data set, the two alleles are named
`A` and `B`.  Some of these markers have a third allele that is a _null allele_.
The _null allele_ does not appear in any reads from the sequencing machine (it is
associated with variation that interferes with the enzyme cut-site used to prepare
the DNA libraries).  Typically these null alleles are a big problem; however, this
data set is based on high enough read depth, that the presence of a null allele can
be ascertained in both homozygous and heterozygous form, so they can be used as
a third allele at markers where they exist.  These null alleles are denoted by
`O` in this dataset.  There are no missing genotypes in the data.

In order to manipulate these data more easily and prepare them for CKMRsim we will
pivot them into a longer format.
```{r pvl}
long_genos <- beardo_genos %>%
  rename(Indiv = Our_sample) %>%
  pivot_longer(
    cols = -Indiv, 
    names_to = c("Locus", "gene_copy"), 
    names_sep = "\\.", 
    values_to = "Allele"
  )
```

This looks like:
```{r pvlview}
long_genos
```


## Kin finding power analysis assuming no physical linkage

To assess the power of a set of markers for kin finding, CKMRsim requires
the allele freqencies in a particular format.  These steps
calculate the allele frequencies and format them as required:
```{r}
locus_names <- unique(long_genos$Locus)
afreqs_ready <- long_genos %>%
  count(Locus, Allele) %>%  
  group_by(Locus) %>%
  mutate(
    Freq = n / sum(n),
    Chrom = "Unk",
    Pos = as.integer(factor(Locus, levels = locus_names))
  ) %>%
  ungroup() %>%
  select(Chrom, Pos, Locus, Allele, Freq) %>%
  arrange(Pos, desc(Freq)) %>%
  mutate(AlleIdx = NA,
         LocIdx = NA) %>%
  filter(!is.na(Allele)) %>%
  reindex_markers()
```

The allele frequencies look like this:
```{r}
afreqs_ready
```

These allele frequencies then get compiled into an R object
that includes the results of a number of calculations that account for genotyping
error and a number of matrices that allow rapid simulation of kin pairs from the
data.

This takes a little while because it is a fairly large
data set.  But not more than a minute on my laptop.
```{r create_ckmr, cache=cache_chunks}
ckmr <- create_ckmr(
  D = afreqs_ready,
  kappa_matrix = kappas[c("PO", "FS", "HS", "HAN", "U"), ],
  ge_mod_assumed = ge_model_TGIE,
  ge_mod_true = ge_model_TGIE,
  ge_mod_assumed_pars_list = list(epsilon = 0.005),
  ge_mod_true_pars_list = list(epsilon = 0.005)
)
```

The `kappa_matrix` specifies the identify coefficients (the $\kappa$'s) for
the different relationships we want.  The remaining options tell it to
use a fairly generic model for genotyping error with an error rate (`epsilon`) at
which we expect about 1% of the genotypes to have a genotyping error.

The variable `kappas` is a piece
of package data that looks like this:
```{r kappaview}
kappas
```

So, the line 
```r
kappas[c("PO", "FS", "HS", "HAN", "U"), ]
```
is merely picking out the rows from that matrix that we want to focus on: we
want to be prepared to do calculations concerning the relationships of:

- `U`: unrelated
- `HAN`: half aunt-niece (which includes half uncle-niece and half uncle-nephew, etc.)
- `HS`: half sibling
- `FS`: full sibling
- `PO`: parent-offspring


Now we can simulate some log likelihood ratios and plot them to see how they look.
```{r simQs, cache=cache_chunks, message=FALSE}
# This simulates a large number of pairwise genotype probabilites
# at each locus
Qs <- simulate_Qij(
  ckmr, 
  calc_relats = c("PO", "FS", "HS", "HAN", "U"),
  sim_relats = c("PO", "FS", "HS", "HAN", "U") 
)


# In the following, we extract those genotype probabilities in different
# ways to calculate a variety of different log-likelihood ratios
# for different relationships.  

# in this particular case, we are looking at log likelihood ratios
# for the hypothesis of Parent-Offspring vs Unrelated
PO_U_logls <- extract_logls(
  Qs,
  numer = c(PO = 1),
  denom = c(U = 1)
)

# And we can plot the distribution of those logl ratios for each
# of the different true relationships. 
ggplot(
  PO_U_logls,
  aes(x = logl_ratio, fill = true_relat)
) +
  geom_density(alpha = 0.25)

```

Clearly, PO and U should be easily resolved.  And it turns out that physical linkage does 
not affect the distribution of log-likelihood ratios when the true relationship is
either U or PO (so long as the markers are not in linkage disequilibrium).

And we can use importance sampling to estimate false positive rates.
```{r}
mc_sample_simple(
  Qs,
  nu = "PO"
)
```

The FPR gives that probability of falsely declaring an unrelated pair a parent-offspring
pair, for a few different values of the false negative rate.  Clearly, there is no chance, whatsoever, of an unrelated pair being mistaken as a PO pair.

For all other relationship types, the fact of physical linkage is important.
In particular, physical linkage really becomes important when we start to consider
kin pairs that are less related than half-siblings, but not a lot less, for example,
the HAN, or "half-aunt-niece" category. 

## Power for kin-finding while accounting for physical linkage

With CKMRsim, we can simulate likelihood ratios (which are calculated without
reference to the physical linkage) under the influence of physical linkage,
**BUT** In order to do that formally, we need to know where in the genome all these
markers are.  We don't know that, in this case, but we can still get a very good sense for the effect of
linkage by imagining that all these markers are spread throughout an appropriately sized
genome.  Since we are simulating lots of pairs in this way, the exact details of the physical
linkage are not quite as important as if we were trying to calculate likelihoods given the
linkage.

### Make a pseudo genome for these critters

A quick search for "bearded seal cytogenetics" leads us to a paper written in
1967 [@fay1967cytogenetic] which tells us that they have a karyotype of 2n=34. 
That means they have 16 pairs of autosomes and one pair of sex chromosomes.
That is not a huge abundance of chromosomes, but it is not as bad as fruit flies,
which have $2n = 8$---only four pairs of chromosomes.
If you look at pictures of the karyotype, the smallest chromosomes are about 1/4
the size of the largest. Here is a screen grab from the the paper:

![](images/beardo-karyotype.png)

On top of that, a quick web search finds an announcement, not long ago, of [completion
of a draft genome for bearded seals](https://www.dnazoo.org/assemblies/Erignathus_barbatus).
From this we find that the genome length is about 2.4 gigabases.  

Cool.  We
can use those pieces of information ($2n = 34$, smallest chromosome about 1/4 the size
of the largest, and genome length = 2.4 gigabases)
to create a pseudo-genome and then sprinkle our markers into it
in order to get a sense for how much physical linkage will affect the distribution
of the log likelihood ratios.  In this process, we will assume a recombination
rate of 1 cm per megabase (about a 1 in 100 chance of a recombination occurring
within 1 megabase during any meiosis). 

```{r}
# this function is part of the CKMRsim package

# make fake chromosome lengths
fake_chromo_lengths <- geometric_chromo_lengths(
  n = 16,
  L = 2.4,
  sl = 0.25
)
```

Here is a plot of those simulated chromosome lengths
scaled, roughly, to correspond to the sizes of the chromosomes
in the figure above, on your screen:
```{r, fig.height=1}
fake_chromo_lengths$chrom_length_plot
```

Now that we have that approximate genome to play with, let's go ahead and randomly
place our variants into it.
```{r}
set.seed(5)
afreqs_link <- sprinkle_markers_into_genome(afreqs_ready, fake_chromo_lengths$chrom_lengths)
```

Have a look at the output.  The original Locus names are there,
but each is placed on a chromosome (the `fc` in `fc01` stands for "fake chromosome").


Now we can make a new CKMR object that has these (fake) physical-location data for
the markers.
```{r ckmr_link, cache=cache_chunks}
ckmr_link <- create_ckmr(
  D = afreqs_link,
  kappa_matrix = kappas[c("PO", "FS", "HS", "HAN", "U"), ],
  ge_mod_assumed = ge_model_TGIE,
  ge_mod_true = ge_model_TGIE,
  ge_mod_assumed_pars_list = list(epsilon = 0.005),
  ge_mod_true_pars_list = list(epsilon = 0.005)
)
```

And, now, to simulate with physical linkage, we use the `simulate_Qij()` function
with the `unlinked = FALSE` option,
but we also need to include information about the pedigrees corresponding
to each relationship.  That information is in the package data object
`pedigrees`.


```{r Qs_link_BIG, cache=cache_chunks, results='hide', warning=FALSE, message=FALSE, echo=TRUE}
Qs_link_BIG <- simulate_Qij(
  ckmr_link, 
  calc_relats = c("PO", "FS", "HS", "HAN", "U"),
  sim_relats = c("PO", "FS", "HS", "HAN", "U"),
  unlinked = FALSE, 
  pedigree_list = pedigrees
)
```

Here we plot the densities of the PO/U log likelihood ratio for the 
different true relationships:
```{r}
# We save the plot so that we can use it
# later to compare to our observed values
PO_U_gg <- Qs_link_BIG %>%
  extract_logls(numer = c(PO = 1), denom = c(U = 1)) %>%
  ggplot(aes(x = logl_ratio, fill = true_relat)) +
  geom_density(alpha = 0.25) +
  ggtitle("PO/U Logl Ratio")

PO_U_gg
```


Aha!  When we simulate those likelihood ratios whilst taking account of
physical linkage, we see that there is a lot more spread in the distributions,
(except for the PO or U relationships, as we mentioned before)
and, consequently, a whole lot more overlap.

Now, let us look at things when we use other likelihood ratios.
For example to distinguish between Full Sibs and
Unrelated individuals, we would use the FS/U log-likelihood ratio:
```{r}
FS_U_gg <- Qs_link_BIG %>%
  extract_logls(numer = c(FS = 1), denom = c(U = 1)) %>%
  ggplot(aes(x = logl_ratio, fill = true_relat)) +
  geom_density(alpha = 0.25) +
  ggtitle("FS/U Logl Ratio")

FS_U_gg
```

Looking at the FS and U curves there, it is pretty clear that they are
very well separated, but, it is also clear that if only this FS/U log-likelihood
ratio were used, then POs would be put into the FS category.  

But don't despair! If you want to distinguish PO from FS, you should use the
PO/FS logl ratio! Here it is for distinguishing between PO and FS:
```{r}
PO_FS_gg <- Qs_link_BIG %>%
  extract_logls(numer = c(PO = 1), denom = c(FS = 1)) %>%
  ggplot(aes(x = logl_ratio, fill = true_relat)) +
  geom_density(alpha = 0.25) +
  ggtitle("PO/FS Logl Ratio")

PO_FS_gg
```

Here for the hypothesis of FS versus HS:
```{r}
FS_HS_gg <- Qs_link_BIG %>%
  extract_logls(numer = c(FS = 1), denom = c(HS = 1)) %>%
  ggplot(aes(x = logl_ratio, fill = true_relat)) +
  geom_density(alpha = 0.25) +
  ggtitle("FS/HS Logl Ratio")

FS_HS_gg
```


And finally for HS versus HAN:
```{r}
HS_HAN_gg <- Qs_link_BIG %>%
  extract_logls(numer = c(HS = 1), denom = c(HAN = 1)) %>%
  ggplot(aes(x = logl_ratio, fill = true_relat)) +
  geom_density(alpha = 0.25) +
  ggtitle("HS/HAN Logl Ratio")

HS_HAN_gg
```

Aha! There is some overlap between HAN and HS, so we will need to keep that in
mind, since we don't want to mistake any HANs for HSs.


When using the HS/HAN log-likelihood ratio, we can see how many Unrelated pairs might conceivably
get in there.  We can use importance sampling when the truth is U, and we can use the distribution
of unlinked markers for that (because linkage does not affect the distribution of the log likelihoods
in unrelated pairs), and we can use the linked simulations for calculating the False Negative 
Rates of the half-siblings:
```{r}
mc_sample_simple(
  Q = Qs,
  Q_for_fnrs = Qs_link_BIG,
  nu = "HS",
  de = "HAN",
  method = "IS"
)
```

Good.  There is clearly no chance that an unrelated individual would be incorrectly
called an HS based on the HS/HAN log-likelihood ratio.

But, what about the chance that a HAN will be mistaken for an HS?  We can use
`mc_sample_simple()` for this, and we don't have to do any importance sampling,
because there just aren't that many HAN pairs (relative to the number of U pairs):
```{r}
mc_sample_simple(
  Q = Qs_link_BIG,
  nu = "HS",
  de = "HAN",
  tr = "HAN",
  method = "vanilla"
)
```

This suggests that if we set a threshold $\Lambda^*_\mathrm{HS/HAN} = 6.3$ then we would expect
to be missing only about 10% of the true HS pairs, and any HAN pairs would only have a 1.7% chance
of having a $\Lambda_\mathrm{HS/HAN} > \Lambda^*_\mathrm{HS/HAN}$.  (Keeping in mind that
these are approximations made by sprinkling loci into a pseudo-genome.) 

Looking at all of these is quite informative.  It suggests that the order that
we will want to pursue our kin-finding in is:

1. Find all PO pairs by high PO/U and also PO/FS > 0.
2. Once we have the PO pairs, we remove them from futher consideration
and identify the FS pairs.  For that we will look for pairs with FS/HS above -20 or so.
Obviously no
unrelateds will be anywhere near that, but we could still check that with
the importance sampling.
3. Once we have the PO and FS individuals we will compute the HS/HAN
logl_ratios for the remaining pairs and then set the cutoff at what we calculated above, with
an FNR of about 10% or 20%.  But we will want to investigate the empirical
distribution of all those values, too, to see if we can see a HAN bump.



## Doing the pairwise comparisons

Because of the ages of these individuals it is probably likely that many of them could
not be PO are FS.  Many probably would be more likely to be GP than HS, all things
being equal, too.  Some of these might be AN instead of HS.  

All those considerations should be taken into account in CKMR. But,
for today, since we don't have the metadata necessary to make those
considerations, we will just look for kin pairs amongst all the pairs
in the data set.

### Make sure we don't have duplicate samples in here

Unless there is _a lot_ of wonky inbreeding going on, it is unlikely that samples
that are not _the same individual_ will have close to 100% matching genotypes.

Here we find all the pairs that mismatch at 500 or fewer loci out of the 2500
that are in the data set:
```{r find_close_matchers, cache=cache_chunks}
matchers <- find_close_matching_genotypes(
  LG = long_genos,
  CK = ckmr,
  max_mismatch = 500
)
matchers
```

There are none.  Cool.  This might be because Mark Bravington and Paul worked these
data over pretty hard before they fell into our hands, and they did this important
step already---either that, or these data were sampled and processed
by incredibly fastidious people,
and/or it is not likely that the same individual is sampled twice.


### Using the pairwise_kin_logl_ratios() function

To compare each individual's genotype to every other individual's genotype to compute
the log-likelihood ratios to find
kin pairs, we use CKMRsim's `pairwise_kin_logl_ratios()` function.  The syntax
is pretty simple: you pass it two long-format tibbles of genotypes (like `long_genos`).
If the data set passed in each time is the same, the function knows to order the
observations and keep only one set of the two comparisons that are made between
each unique sample ID in the dataset.

You can specify the numerator and the denominator for the log likelihood ratios
to be computed. (Also, the function is parallelized, but we don't use
that feature here, because our GitHub actions workflow that renders this
document might not use multiple cores.)

Below, we wrap the whole thing into an `lapply` so that we can run the
`pairwise_kin_logl_ratios()` function four times, to get the different
logl ratios: PO/U, PO/FS, FS/HS, and HS/HAN, and then present the results
in a tidy tibble.

### Doing pairwise comparisons somewhat systematically

So, we only really have four columns to make: PO/U, PO/FS, FS/HS, and HS/HAN.
I am going to make them all and then put them into a big data frame. The
number of markers is the same every time.
```{r pairwise-comps-4way, cache=cache_chunks, message=FALSE}
pw_4_LRTs <- lapply(
  X = list(
    POU = c("PO", "U"),
    POFS = c("PO", "FS"),
    FSHS = c("FS", "HS"),
    HSHAN = c("HS", "HAN")
  ),
  FUN = function(x) {
    pairwise_kin_logl_ratios(
      D1 = long_genos, 
      D2 = long_genos, 
      CK = ckmr,
      numer = x[1],
      denom = x[2],
      num_cores = 8
    )
  }
) %>%
  bind_rows(
  .id = "lr_type"
) %>%
  pivot_wider(names_from = lr_type, values_from = logl_ratio)

```

And now we can see how things compare to our simulations.

### Finding the PO pairs 

First, let's look at all the pairs that had a PO/U logl > 0.
```{r}
topPO <- pw_4_LRTs %>%
  arrange(desc(POU)) %>%
  filter(POU > 0)

topPO
```

We can plot those pairs against the simulated PO/U logls that
we made previously.
```{r}
set.seed(54) # for the jittering
PO_U_gg +
  geom_jitter(
    data = topPO,
    mapping = aes(x = POU, y = -0.002, colour = POFS > 0),
    width = 0, 
    height = 0.001, 
    fill = NA,
    shape = 21
  )
```

The points below the $y=0$ line are the PO/U logls for those 11 pairs.
They are colored green if their PO/FS logl is greater than 0.

From this we see 5 pairs that look like solid PO pairs.  Those 5, on average
have lower PO/U logls than we would have expected from the simulations, which is
possibly due to the genotyping error rate in the data being higher than the values
that we specified.  

There is something wonky thing going on with the 6th green point.
I thought at first that maybe it was inbred
full siblings, but then it would have a higher FSHS.  Weird.  But, for now,
we will call all 6 of those PO pairs, but I would be pretty skeptical about
that 6th one.

Here we create a table of likely PO pairs:
```{r}
likelyPO <- topPO %>%
  filter(POFS > 20)
```

### Finding full sibling pairs

To do this, we take the remaining pairs and look at their FS/HS logl values, let's start
by taking anything with an FS/HS logl > -20.
```{r}
topFS <- pw_4_LRTs %>%
  anti_join(likelyPO, by = c("D2_indiv", "D1_indiv")) %>%  # remove the PO pairs 
  arrange(desc(FSHS)) %>%
  filter(FSHS > -20)
topFS
```

That is only four individuals.  Let's see where they fall out against the simulated
distribution:
```{r}
set.seed(54) # for the jittering
FS_HS_gg +
  geom_jitter(
    data = topFS,
    mapping = aes(x = FSHS, y = -0.002),
    width = 0, 
    height = 0.001, 
    fill = NA,
    shape = 21
  )
```


So, that is four individuals that look like full siblings (since PO has
already been removed). Once again, their FS/HS logl values are trending
a little lower than what we expect, which might intimate that our model
for the genetic data (genotyping error rates) might not be spot on.

But those four individuals still look like full-siblings.

### Looking for half-siblings

So, finally let's start looking for half-siblings.
```{r}
remaining <- pw_4_LRTs %>%
  anti_join(bind_rows(likelyPO, topFS), by = c("D2_indiv", "D1_indiv"))
```

We can have a look at the bumps we might see on the extreme right end of the
unrelated distribution and then the others.
```{r}
all_HSHAN_logsl <- ggplot(remaining, aes(x = HSHAN)) + 
  geom_histogram(bins = 30)
```

Plot all of them:
```{r}
all_HSHAN_logsl +
  ggtitle("All Remaining Pairs")
```

So, the HSHAN logls of almost all of the remaining pairs are quite low.
But, let us have a look at the extreme right edge there:
```{r}
all_HSHAN_logsl +
  xlim(-45, NA) +
  ggtitle("Pairs with HSHAN > -45")
```

Aha! There are probably some half-sibling pairs.
There are also probably some half-aunt-niece pairs
in there.  Let's look at all of those as points.

```{r}
set.seed(52)
HS_HAN_gg + 
  geom_jitter(
    data = remaining %>% filter(HSHAN > -65),
    mapping = aes(x = HSHAN, y = -0.02),
    width = 0, 
    height = 0.01, 
    fill = NA,
    shape = 21
  ) +
  coord_cartesian(xlim = c(-65, 125), ylim = c(NA, 0.04))
```

Ooh! That is a pretty neat way to look at it.  With over roughly a million unrelated pairs,
in total, we see that quite a few of them are on the far right edge of the distribution
for the unrelated pairs.  Then a smattering of individuals in the HAN region, and then
a sizable break after $x=0$ till a cluster of points that are right in the middle
of what is expected for half siblings. Finally there is one individual way to
the right, that is not really where you would expect a half-sibling to sit.

We can look at all of those, and we find 18 likely half-sibs, and one
that is probably a PO pair, but may involve some inbreeding:
```{r}
remaining %>% 
  filter(HSHAN > 0) %>% 
  arrange(HSHAN) %>%
  as_data_frame()
```

Once we have done this initial round of kin-finding, we would typically go back and check it with
the meta data.  Keeping in mind that individuals in the HS categories could be
grandparent-grandchild, or, much less likely, full-aunt-niece.

## Check the distribution of all pairs against the simulated unrelated pairs

Because an overwhelming majority of the pairs should be (largely) unrelated,
the observed distribution of logls from all pairs should be close to what
is simulated for unrelated individuals.

We can plot the densities and compare


Here we do it for the $\Lambda_{PO/U}$.  The red-filled density is the
simulated (theoretical) curve, and the unfilled black line is what
was observed.
```{r}
simU_POU <- Qs %>%
  extract_logls(numer = c(PO = 1), denom = c(U = 1)) %>% 
  filter(true_relat == "U")

ggplot() +
  geom_density(
    data = simU_POU,
    mapping = aes(x = logl_ratio),
    fill = "red",
    alpha = 0.3
  ) +
  geom_density(
    data = pw_4_LRTs, 
    mapping = aes(x = POU)
  )
```

Whoa! That is somewhat unexpected.  We expect to have a little bump in the observed
curve on the right hand side, because there should be some pairs that are not
completely unrelated.  But the long tail to the left is a hard one to explain.

That fat tail on the left in the observed distribution remains, even for a likelihood
ratio that should not be too affected by the genotyping error model ($\Lambda_{HS/HAN}$):



```{r}
simU_HSHAN <- Qs %>%
  extract_logls(numer = c(HS = 1), denom = c(HAN = 1)) %>% 
  filter(true_relat == "U")

ggplot() +
  geom_density(
    data = simU_HSHAN,
    mapping = aes(x = logl_ratio),
    fill = "red",
    alpha = 0.3
  ) +
  geom_density(
    data = pw_4_LRTs, 
    mapping = aes(x = HSHAN)
  )
```

This is interesting.  As a population geneticist I would want to follow up on this
to figure out what feature of our genetic data or of the population under study is leading
to this distortion from what we expect.  There might be an interesting story there!

## Conclusion

One big take-home message here is that it takes a lot of good genetic
markers to be able to reliably distinguish half-siblings from 
half-aunt niece relationships.  This is a tremendously robust data
set, and the distinction between those groups seems reasonably clear,
but with fewer markers it would be a lot harder.

Don't sell yourself short on the genetic markers!!


## Postscript: Following up on that distorted distribution

_(This was added on Dec 12, 2022, after the workshop)_

The long left tail on the empirical distribution of likelihood ratios
got me thinking that genotyping error rates might be a little higher
than expected in some of the markers.  In particular, I wanted to
follow up on the null alleles (the `O` alleles) that were called in
the data set.  There is a chance that the those genotypes are not called
as accurately as they are believed to be.

One way to explore this is to look at the observed frequencies of the
genotypes compared to what is expected under Hardy-Weinberg equilibrium.
Eric has a little R package called 
'[whoa](https://github.com/eriqande/whoa)'
that is useful for this purpose.  It has some functions that will let
us plot the observed vs expected frequencies easily.

'whoa' is built to investigate biallelic markers.  Any markers that
have called null alleles are triallelic, so we have to collapse
two alleles down into one, to investigate this.  So, here we go with that.

First we will re-check to see what the the different alleles are in this
data set:
```{r}
long_genos %>%
  count(Allele)
```

Because whoa operates on biallelic markers, we are going to have to lump the `O` allele
into either the `A` category, or the `B` category, or we will lump the
`A` and `B` alleles together and have the null allele be its own category.

The next few sections do those three different ways of lumping using the
following temporary object:
```{r}
lumpies <- long_genos %>% 
  mutate(
    lumpA = ifelse(Allele == "O", "A", Allele),
    lumpB = ifelse(Allele == "O", "B", Allele)
  )
```


### Lump the `A` and `O` alleles together


From `lumpies` this, we can make some 012 matrices:
```{r alump, cache=cache_chunks}
A012 <- lumpies %>%
  mutate(ints = ifelse(lumpA == "A", 0, 1)) %>%
  group_by(Locus, Indiv) %>%
  summarise(geno = sum(ints)) %>%
  pivot_wider(names_from = Indiv, values_from = geno) %>%
  ungroup()

A012_mat <- as.matrix(A012 %>% select(-Locus))
rownames(A012_mat) <- paste("Unk", str_replace(A012$Locus, "^L", ""), sep = "-")
storage.mode(A012_mat) <- "integer"
```

And with that we can stick it into whoa:
```{r}
eobsA <- whoa::exp_and_obs_geno_freqs(d012 = A012_mat)

whoa::geno_freqs_scatter(eobsA, max_plot_loci = 4000)
```
When we lump the nulls in with the `A` allele, it is hard to
see any indication of distortions from the expected genotype
frequencies (`p_exp` on the $x$-axis), and the observed
frequencies (`p_obs` on the $y$ axis).

Note: `geno` in this plot refers to the genotype which is the sum
of the allele integers.  The way the alleles have been lumped here, 
bot `A` and `O` are considered the `0` allele, and `B` is considered
the `1` allele.  So the `0` genotype is the `00` homozygote, the `1` 
genotype is the `01` or `10` heterozygote, and the `2`
genotype is the `11` homozygote.

### Try the same thing, lumping the nulls into the B alleles

```{r blump, cache=cache_chunks}
B012 <- lumpies %>%
  mutate(ints = ifelse(lumpB == "A", 0, 1)) %>%
  group_by(Locus, Indiv) %>%
  summarise(geno = sum(ints)) %>%
  pivot_wider(names_from = Indiv, values_from = geno) %>%
  ungroup()

B012_mat <- as.matrix(B012 %>% select(-Locus))
rownames(B012_mat) <- paste("Unk", str_replace(B012$Locus, "^L", ""), sep = "-")
storage.mode(B012_mat) <- "integer"
```

And with that we can stick it into whoa:
```{r}
eobsB <- whoa::exp_and_obs_geno_freqs(d012 = B012_mat)

whoa::geno_freqs_scatter(eobsB, max_plot_loci = 4000)
```

OK, that is a little more revealing.  We see a little smooshie spot where
we don't have quite as many heterozygotes as we would expect, and there
are a few homozygotes that are at higher observed frequency than we
would expect.

### Now, lump the A and B alleles together

The way the data were processed and presented, the null alleles are being
used as just another allele.  So, we could actually just whittle this down
to the loci that have null alleles in them, and then lump alleles A and B
together into the reference (`0`) allele and let the alternate (`1`)
allele be the null allele.  That should give us a nice picture of any
distortions.

```{r ablump, cache=cache_chunks}
nulls_as_alts <- long_genos %>%
  group_by(Locus) %>%
  filter(any(Allele == "O")) %>%   # keep only loci with null alleles, and that is most of them
  ungroup() %>%
  mutate(ints = ifelse(Allele == "O", 1, 0))

N012 <- nulls_as_alts %>%
  group_by(Locus, Indiv) %>%
  summarise(geno = sum(ints)) %>%
  pivot_wider(names_from = Indiv, values_from = geno) %>%
  ungroup()

N012_mat <- as.matrix(N012 %>% select(-Locus))
rownames(N012_mat) <- paste("Unk", str_replace(N012$Locus, "^L", ""), sep = "-")
storage.mode(N012_mat) <- "integer"
```

And with that we can stick it into whoa:
```{r}
eobsN <- whoa::exp_and_obs_geno_freqs(d012 = N012_mat)

whoa::geno_freqs_scatter(eobsN, max_plot_loci = 4000)
```

And that shows, fairly clearly, a mild degree of:

- Excess of non-null (0) homozygotes at low frequencies (i.e. when there are lots of nulls)
- Excess of null (2) homozygotes at high frequencies (i.e. when there are lots of nulls)
- A deficit of heterozygotes when there are lots of them.

So, this also indicates that there are some markers at which nearly half of the alleles
are null alleles, and things aren't doing so well at those.

### Drop those loci that show these distortions

We could certainly keep track of which of those loci are the worst offenders: they
are clearly the ones with the highest frequency of null alleles.   Let us actually
plot the distribution of those null allele frequencies:
```{r}
null_freqs <- long_genos %>%
  count(Locus, Allele) %>%
  group_by(Locus) %>%
  mutate(rel_freq = n / sum(n)) %>%
  filter(Allele == "O") %>%
  arrange(desc(rel_freq))

ggplot(null_freqs, aes(x = rel_freq)) +
  geom_histogram(binwidth = 0.05, fill = "white", colour = "black")
```

Yep, there is a small handful of loci with very high frequencies of null alleles.

If we look at the last "p_exp vs p_obs" plot above, the cluster of points that
is most notably outside of the expected range are those with:

- `0` genotype p_exp < 0.5 (which means null allele freq > 0.3)
- `1` genotype p_exp < 0.1 (which is near null allele freq > 0.3)

What are we left with if we remove the loci with null allele frequency greater
than 20%?
```{r}
loci_with_nulls_gt20 <- null_freqs %>%
  filter(rel_freq > 0.20)
nrow(loci_with_nulls_gt20)
```
So, that would discard only 173 loci.  Let's do that and see
if the observed and simulated log-likelihood curves are any closer
together.


```{r}
long_genos_dropped <- long_genos %>%
  anti_join(loci_with_nulls_gt20, by = "Locus")
```

Now we can work through the steps we did in the beginning of this:

```{r}
locus_names_lgd <- unique(long_genos_dropped$Locus)
afreqs_ready_lgd <- long_genos_dropped %>%
  count(Locus, Allele) %>%  
  group_by(Locus) %>%
  mutate(
    Freq = n / sum(n),
    Chrom = "Unk",
    Pos = as.integer(factor(Locus, levels = locus_names))
  ) %>%
  ungroup() %>%
  select(Chrom, Pos, Locus, Allele, Freq) %>%
  arrange(Pos, desc(Freq)) %>%
  mutate(AlleIdx = NA,
         LocIdx = NA) %>%
  filter(!is.na(Allele)) %>%
  reindex_markers()
```

Make the CKMR object
```{r create_ckmr_lgd, cache=cache_chunks}
# for this, we will only do PO, HS and U
ckmr_lgd <- create_ckmr(
  D = afreqs_ready_lgd,
  kappa_matrix = kappas[c("PO", "HS", "U"), ],
  ge_mod_assumed = ge_model_TGIE,
  ge_mod_true = ge_model_TGIE,
  ge_mod_assumed_pars_list = list(epsilon = 0.005),
  ge_mod_true_pars_list = list(epsilon = 0.005)
)
```

And simulate some genotypes:
```{r simQs_lgd, cache=cache_chunks, message=FALSE}
# This simulates a large number of pairwise genotype probabilites
# at each locus
Qs_lgd <- simulate_Qij(
  ckmr_lgd, 
  calc_relats = c("PO", "HS", "U"),
  sim_relats = c("PO", "HS", "U") 
)
```

Now, compute pairwise log-likelihoods.  We will just look at comparing
PO/U and HS/U:
```{r pairwise-comps-4way_lgd, cache=cache_chunks, message=FALSE}
pw_2_LRTs_lgd <- lapply(
  X = list(
    POU = c("PO", "U"),
    HSU = c("HS", "U")
  ),
  FUN = function(x) {
    pairwise_kin_logl_ratios(
      D1 = long_genos_dropped, 
      D2 = long_genos_dropped, 
      CK = ckmr_lgd,
      numer = x[1],
      denom = x[2],
      num_cores = 8
    )
  }
) %>%
  bind_rows(
  .id = "lr_type"
) %>%
  pivot_wider(names_from = lr_type, values_from = logl_ratio)

```


Now we can compare those things.

#### PO/U logl ratios

```{r}
simU_POU_lgd <- Qs_lgd %>%
  extract_logls(numer = c(PO = 1), denom = c(U = 1)) %>% 
  filter(true_relat == "U")

ggplot() +
  geom_density(
    data = simU_POU_lgd,
    mapping = aes(x = logl_ratio),
    fill = "red",
    alpha = 0.3
  ) +
  geom_density(
    data = pw_2_LRTs_lgd, 
    mapping = aes(x = POU)
  )
```

There, we see a minor improvement in the left tail.  


#### HS/U logl ratios

```{r}
simU_HSU_lgd <- Qs_lgd %>%
  extract_logls(numer = c(HS = 1), denom = c(U = 1)) %>% 
  filter(true_relat == "U")

ggplot() +
  geom_density(
    data = simU_HSU_lgd,
    mapping = aes(x = logl_ratio),
    fill = "red",
    alpha = 0.3
  ) +
  geom_density(
    data = pw_2_LRTs_lgd, 
    mapping = aes(x = HSU)
  )
```

### What happens if we drop loci with null allele freq > 0.2?

How about if we go more extreme?  We might end up losing more than
half of the loci this way, but it could be instructive to see if these
loci are the ones that are primarily responsible for that left tail.

We will focus on PO/U here.
```{r}
loci_with_nulls_gt2 <- null_freqs %>%
  filter(rel_freq > 0.02)
nrow(loci_with_nulls_gt2)
```
So, that would discard 1285 loci.  That is not viable, but
we will do it here in the name of exploration.
```{r}
long_genos_d2 <- long_genos %>%
  anti_join(loci_with_nulls_gt2, by = "Locus")
```

```{r}
locus_names_lgd2 <- unique(long_genos_d2$Locus)
afreqs_ready_lgd2 <- long_genos_d2 %>%
  count(Locus, Allele) %>%  
  group_by(Locus) %>%
  mutate(
    Freq = n / sum(n),
    Chrom = "Unk",
    Pos = as.integer(factor(Locus, levels = locus_names))
  ) %>%
  ungroup() %>%
  select(Chrom, Pos, Locus, Allele, Freq) %>%
  arrange(Pos, desc(Freq)) %>%
  mutate(AlleIdx = NA,
         LocIdx = NA) %>%
  filter(!is.na(Allele)) %>%
  reindex_markers()
```

Make the CKMR object
```{r create_ckmr_lgd2, cache=cache_chunks}
# for this, we will only do PO, HS and U
ckmr_lgd2 <- create_ckmr(
  D = afreqs_ready_lgd2,
  kappa_matrix = kappas[c("PO", "HS", "U"), ],
  ge_mod_assumed = ge_model_TGIE,
  ge_mod_true = ge_model_TGIE,
  ge_mod_assumed_pars_list = list(epsilon = 0.005),
  ge_mod_true_pars_list = list(epsilon = 0.005)
)
```

And simulate some genotypes:
```{r simQs_lgd2, cache=cache_chunks, message=FALSE}
# This simulates a large number of pairwise genotype probabilites
# at each locus
Qs_lgd2 <- simulate_Qij(
  ckmr_lgd2, 
  calc_relats = c("PO", "U"),
  sim_relats = c("PO", "U") 
)
```

Now, compute pairwise log-likelihoods.  We will just look at comparing
PO/U and HS/U:
```{r pairwise-comps-2way_lgd2, cache=cache_chunks, message=FALSE}
pw_1_LRTs_lgd2 <- lapply(
  X = list(
    POU = c("PO", "U")
  ),
  FUN = function(x) {
    pairwise_kin_logl_ratios(
      D1 = long_genos_d2, 
      D2 = long_genos_d2, 
      CK = ckmr_lgd2,
      numer = x[1],
      denom = x[2],
      num_cores = 8
    )
  }
) %>%
  bind_rows(
  .id = "lr_type"
) %>%
  pivot_wider(names_from = lr_type, values_from = logl_ratio)

```

#### PO/U logl ratios with nulls > 0.02 tossed

```{r}
simU_POU_lgd2 <- Qs_lgd2 %>%
  extract_logls(numer = c(PO = 1), denom = c(U = 1)) %>% 
  filter(true_relat == "U")

ggplot() +
  geom_density(
    data = simU_POU_lgd2,
    mapping = aes(x = logl_ratio),
    fill = "red",
    alpha = 0.3
  ) +
  geom_density(
    data = pw_1_LRTs_lgd2, 
    mapping = aes(x = POU)
  )
```
That is a lot closer, of course it is using fewer loci.

### What happens if we increase the assumed and simulated genotyping error rates

It could be that genotyping error rates are greater, in actuality, than
what we are assuming in these simulations and calculations.  Let's see
what happens if we crank them up by a factor of 3, from 0.005 to 0.015.

We will use the data set with the null allele freqs < 0.02, since it
is a little smaller and doesn't take quite as long to do this...

```{r create_ckmr_lgd2_015, cache=cache_chunks}
# for this, we will only do PO, HS and U
ckmr_lgd2_015 <- create_ckmr(
  D = afreqs_ready_lgd2,
  kappa_matrix = kappas[c("PO", "HS", "U"), ],
  ge_mod_assumed = ge_model_TGIE,
  ge_mod_true = ge_model_TGIE,
  ge_mod_assumed_pars_list = list(epsilon = 0.015),
  ge_mod_true_pars_list = list(epsilon = 0.015)
)
```

And simulate some genotypes:
```{r simQs_lgd2_015, cache=cache_chunks, message=FALSE}
# This simulates a large number of pairwise genotype probabilites
# at each locus
Qs_lgd2_015 <- simulate_Qij(
  ckmr_lgd2_015, 
  calc_relats = c("PO", "U"),
  sim_relats = c("PO", "U") 
)
```

Now, compute pairwise log-likelihoods.  We will just look at comparing
PO/U and HS/U:
```{r pairwise-comps-2way_lgd2_015, cache=cache_chunks, message=FALSE}
pw_1_LRTs_lgd2_015 <- lapply(
  X = list(
    POU = c("PO", "U")
  ),
  FUN = function(x) {
    pairwise_kin_logl_ratios(
      D1 = long_genos_d2, 
      D2 = long_genos_d2, 
      CK = ckmr_lgd2_015,
      numer = x[1],
      denom = x[2],
      num_cores = 8
    )
  }
) %>%
  bind_rows(
  .id = "lr_type"
) %>%
  pivot_wider(names_from = lr_type, values_from = logl_ratio)

```

#### PO/U logl ratios with nulls > 0.02 tossed and genotyping rate of 0.015

```{r}
simU_POU_lgd2_015 <- Qs_lgd2_015 %>%
  extract_logls(numer = c(PO = 1), denom = c(U = 1)) %>% 
  filter(true_relat == "U")

ggplot() +
  geom_density(
    data = simU_POU_lgd2_015,
    mapping = aes(x = logl_ratio),
    fill = "red",
    alpha = 0.3
  ) +
  geom_density(
    data = pw_1_LRTs_lgd2_015, 
    mapping = aes(x = POU)
  )
```

That is a little closer.  

## Wrap Up

Well, that has been a somewhat _ad hoc_ analysis of genotyping error rates
and simulated vs observed distributions.  There would be more formal ways
of doing this (and surely, even the _ad hoc_ explorations here should be wrapped
up into a function), but this gives a flavor for some explorations that could
be done.

