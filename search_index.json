[["index.html", "Close-kin mark-recapture: theory and practice — Spokane, Washington, USA Course Overview Workshop schedule Resources Setting up your computer A word about the ‘renv’ package A word about the TMB package", " Close-kin mark-recapture: theory and practice — Spokane, Washington, USA Paul B. Conn and Eric C. Anderson November 6, 2022 Course Overview This is the website/book associated with the Close-kin mark-recapture: theory and practice workshop to be held at The Wildlife Society meetings Nov 6, 2022 in Spokane, Washington. Workshop schedule An approximate schedule for the workshop is as follows. Note that when a session has slides for a lecture, they are linked below. Time Description Instructor(s) 8:00–8:45 Close-kin mark-recapture: An overview (slides) P. Conn 8:45–9:30 An introduction to genetic data and inheritance (slides) E. Anderson 9:30–9:45 Break 9:45–10:30 Statistical inference for CKMR estimation (slides) P. Conn 10:30–11:15 Kin finding (slides) E. Anderson 11:15–12:00 Designing a CKMR experiment (slides) P. Conn 12:00–1:00 Lunch 1:00–5:00 R/TMB labs (full day participants only) P. Conn/E. Anderson Workshop attendees had the option of registering for half-day or full-day sessions. The first half will consist almost entirely of lectures, with no previous programming experience needed. The second half will involve labs and exercises conducted in R and/or Template Model Builder (at the user’s discretion). Full day participants should use the following set of instructions to set up their computers prior to the workshop. Please do this within no more than a day or two of the workshop, as the materials will be evolving up to the day of launch! (Additionally, if you follow the instructions below, any new changes to the afternoon lab materials will be fast and easy to get). Resources All the materials for the workshop, including this “book” and all of the slides are located on github at https://github.com/eriqande/tws-ckmr-2022 The “website” version of the course which serves up this book and the slides is available at https://eriqande.github.io/tws-ckmr-2022/ These course materials will remain publicly available in perpetuity at the above addresses. We might occasionally update them as well. There is also additional material and examples that may be of interest at https://closekin.github.io/ Setting up your computer This is only really necessary if you are signed up for the full day course This course covers topics in close-kin mark recapture, and the second half of the course relies heavily on the R programming language. In order to follow along with the code and be successful in running all of the examples, it will be helpful (if not imperative) for full-day workshop participants to have recent versions of R and RStudio. Step 1. Install recent versions of R and RStudio The workshop materials were developed using: R versions 4.1 and 4.2 Rstudio Version &gt;= 2022.07.01 If you have an older version of either of those applications, you should install the latest. Important Several of the packages must be compiled locally on your laptop, and the TMB package operates by compiling C++ code. Accordingly, in addition to installing R, and RStudio, you must have a compile/build chain on your computer: On a Mac, you need to do sudo xcode-select --install as described here. Note that this requires admin privileges, so, if your computer is administered by your agency or university IT department, get this done before arriving in Spokane. For Windows, you must download and install the Rtools as available here. Also very important: The slides for our lectures are rendered using RStudio’s new Quarto engine, which is a successor to RMarkdown/knitr. This must be enabled on your system. The best way is probably to install the command line interface for Quarto by following the instructions here: https://quarto.org/docs/get-started/ Once you have installed that, you should close and then reopen your RStudio project. We have tested the workshop materials on several platforms: a Mac with an Intel chip running BigSur OSX 11 a Mac with an M1 (Apple silicon) chip running Monterey version 12.6 a PC running Windows 10. We suspect it will also work on most other Mac or Windows operating systems. Step 2. Make sure that you have git installed on your system If you are on a Mac and successfully did sudo xcode-select --install, then you will have git. If you are on a PC and you do not have git, then follow the instructions in the excellent (HappyGitWithR)[https://happygitwithr.com/] book, specifically the “highly recommended” option 1. A further word on git Although the distribution our workshop materials depends heavily on git, and the cloud-based code management system GitHub, that is built upon git, we won’t have the time to delve deeply into these topics. You can do everything you need to do for this workshop without having an account on GitHun, but, if you are interested in version control for your analyses, and you are interested in using GitHub to share and present the results of your research, then you really will want to become proficient with both git and GitHub. Once again, the online book https://happygitwithr.com/ is highly recommended. Step 3. Get the workshop materials from GitHub with RStudio Once git is installed and RStudio knows where to find it, RStudio can use it to download the workshop materials from GitHub. Follow these steps: Open RStudio From the dropdown menus, choose File -&gt; RStudio In the resulting pop-up window choose and click “Version Control”: In the next screen of the “wizard” choose “Git”: In the next screen of the wizard, paste the following URL into the Repository URL box. https://github.com/eriqande/tws-ckmr-2022.git Then use the “Browse” button to tell where you want the project to be stored on your computer (that is up to you!), click “Open in new session” (why not—no reason to close out whatever you were working on in another RStudio project), and then click “Create Project”: RStudio then downloads the project and opens it for you. It also detects that the project is using the ‘renv’ package (see below) and tells you how to get all the packages you need. It should look something like this: . To get all the packages, paste these lines into your R console in RStudio: install.packages(&quot;rmarkdown&quot;) renv::restore() That should start with ‘renv’ giving you a list of all the packages that will be installed or updated in the repository-local library tree (this should not change versions of packages in your own use-wide or system-wide collection of packages), and it will ask something like: Do you want to proceed? [y/N]: Enter y. That should launch what could be a fairly lengthy process of downloading, compiling (a few, at least) and installing all the R packages we need, and their dependencies. That should do it, and if it works for most everyone in the course with relatively few hitches, then it is a testament to how well the ‘renv’ package is implemented. If there are some hiccups, we will try our best to help you deal with them. Updating the project It is possible that the course instructors may update the project repository with new information, code, or content after you have followed the steps above to do the initial installation. Fortunately, it is easy to get those updates from GitHub. Updating your project can be done in these two easy steps: Pull the changes down from GitHub. In RStudio, this means hitting the “Pull” button in the Git panel: Then in the R console, execute the command. renv::restore() That’s it! A word about the ‘renv’ package Our work will require a number of packages that can be found in binary form on CRAN. As well as several that require compilation from source on GitHub. This is why the compile/build chain (see above) is essential. This year, we are using the ‘renv’ package to help with installing the necessary packages in an isolated R library on your computer. The ‘renv’ package guides the installation of all the packages (with specific version numbers that we have tested for this workshop) into a local R library associated with the workshop’s RStudio project. This means that installing all these new packages will not overwrite your current R library tree. So, nothing that we do should change the way your current R setup works in other projects (fingers crossed!). A word about the TMB package In the full day workshop we will make some use of Template Model Builder (TMB); attendees might wish to familiarize themselves with how it works by reading some of its documentation, such as that at https://kaskr.github.io/adcomp/Introduction.html). For the mathematically or computationally inclined, the article about TMB on arXiv might be a fun read. "],["ckmr-thought-experiments-and-labs.html", "Session 1 CKMR thought experiments and labs 1.1 Afternoon schedule 1.2 Thought experiments", " Session 1 CKMR thought experiments and labs In the second half of this course, we’re going to switch gears and delve into some code. But first, we’re going to conduct a few thought experiments to try to get you to think critically about some of the CKMR concepts we’ve covered so far. We’ll also be switching from slides to this “book” - hopefully this will be a useful resource for those of you who want to look back at course content. 1.1 Afternoon schedule An approximate schedule for the afternoon is 1:00 - 1:30 Thought experiments 1:30 - 2:30 Kin finding lab 2:30 - 2:45 Break 2:45 - 3:30 White shark estimation example 3:30 - 4:30 CKMR Design 4:30 - 5:00 Open! Feel free to play with code or ask us questions 1.2 Thought experiments We think it would be useful for participants to break into small groups for this one. So let’s do that. Note that there are not necessarily any right or wrong answers to these exercises - but we’re interested to hear what people come up with! 1.2.1 Thought experiment 1 Assume that mitochondrial haplotype diversity is high, so that we can definitely tell MHSPs from PHSPs. What might be causes for the number of PHSPs being significantly greater than the number of MHSPs? 1.2.2 Thought experiment 2 What sampling or population conditions might lead to negative bias in CKMR abundance estimates? How about positive bias in abundance estimates? 1.2.3 Thought experiment 3 Imagine that we are conducting a CKMR experiment using POPs. Given that CKMR estimators of abundance are in essence backdated to the year of the offspring’s birth, how might we sample animal populations to get better precision in the most recent years? 1.2.4 Thought experiment 4 Suppose we are thinking about using CKMR to estimate the abundance of a migratory goose population, where males and females routinely form lifelong pair bonds, and goslings stay with their parents for the first year of life or so. Genetics samples are available from parts collection surveys (from hunter harvests), and the goal is to estimate adult abundance for a particular flyway. What are some things to consider when designing a CKMR study with these data? "],["kin-finding-lab.html", "Session 2 Kin-finding lab 2.1 Looking at the genetic data and pivoting it 2.2 Kin finding power analysis assuming no physical linkage 2.3 Power for kin-finding while accounting for physical linkage 2.4 Doing the pairwise comparisons 2.5 Check the distribution of all pairs against the simulated unrelated pairs 2.6 Conclusion", " Session 2 Kin-finding lab In this session, we are going to get our hands dirty with a lovely data set of genetic data from 1,484 bearded seals and use those data to find kin pairs from amongst the \\({1,484 \\choose 2} = 1,100,386\\) pairs that can be formed from all those samples. This data set includes 2,569 genetic markers. These markers were filtered down for quality and reliability from a much larger set. We won’t talk about that process, here, but keep in mind that a huge part of a successful CKMR project involves getting and curating a quality set of genetic markers. We will first estimate how much power we expect to have for identifying kin pairs with this marker set, and then we will actually do the kin-finding. Both of these steps will be done using the R package ‘CKMRsim’ that Eric wrote. It is available from GitHub at https://github.com/eriqande/CKMRsim and its online documentation can be read at: https://eriqande.github.io/CKMRsim/. If you want to use ‘CKMRsim’ yourself in a different project, you would need to install it like this: remotes::install_github(&quot;eriqande/CKMRsim&quot;) However, we have already included it in the tws-ckmr-2022 project using ‘renv’, so you don’t have to install it now. Before proceeding, we will load all of the libraries that we will be using for this session. Additionally, we will download and install the binary of the mendel program so that we can simulate genetic markers with physical linkage. library(tidyverse) library(CKMRsim) # the next step tests to see if mendel was already installed. # if not, it installs it if(system.file(&quot;bin&quot;, package = &quot;CKMRsim&quot;) == &quot;&quot;) { install_mendel(Dir = system.file(package = &quot;CKMRsim&quot;)) } 2.1 Looking at the genetic data and pivoting it We load the genetic data from an RDS file: beardo_genos &lt;- read_rds(&quot;data/beardo-genos.rds&quot;) Here are the first 10 rows and 9 columns of that data set: beardo_genos[1:10, 1:9] ## # A tibble: 10 × 9 ## Our_sample L252.1 L252.2 L253.1 L253.2 L472.1 L472.2 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2010BS40 B B A O A B ## 2 EB20GAM002 A A A O A B ## 3 EB16GAM070 A A B B B B ## 4 SH-G18-04 A A A A B B ## 5 SH-S04-05 A B A A A A ## 6 09BS8 B B A B A A ## 7 EB17GAM073 A A A A A B ## 8 EB13GAM022 A A B O A B ## 9 EB17GAM059 A A A A B O ## 10 EB05NOM003 A A A B A B ## # … with 2 more variables: L567.1 &lt;chr&gt;, L567.2 &lt;chr&gt; ## # ℹ Use `colnames()` to see all variable names The full data set has 1484 rows and 5139 columns. This is a standard genotype format. The first column gives the sample name and every subsequent pair of columns gives the alleles found in the sample at a genetic marker or “locus”. These markers are single nucleotide polymorphism (SNP) markers. These markers are typically biallelic, and in this data set, the two alleles are named A and B. Some of these markers have a third allele that is a null allele. The null allele does not appear in any reads from the sequencing machine (it is associated with variation that interferes with the enzyme cut-site used to prepare the DNA libraries). Typically these null alleles are a big problem; however, this data set is based on high enough read depth, that the presence of a null allele can be ascertained in both homozygous and heterozygous form, so they can be used as a third allele at markers where they exist. These null alleles are denoted by O in this dataset. There are no missing genotypes in the data. In order to manipulate these data more easily and prepare them for CKMRsim we will pivot them into a longer format. long_genos &lt;- beardo_genos %&gt;% rename(Indiv = Our_sample) %&gt;% pivot_longer( cols = -Indiv, names_to = c(&quot;Locus&quot;, &quot;gene_copy&quot;), names_sep = &quot;\\\\.&quot;, values_to = &quot;Allele&quot; ) This looks like: long_genos ## # A tibble: 7,624,792 × 4 ## Indiv Locus gene_copy Allele ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2010BS40 L252 1 B ## 2 2010BS40 L252 2 B ## 3 2010BS40 L253 1 A ## 4 2010BS40 L253 2 O ## 5 2010BS40 L472 1 A ## 6 2010BS40 L472 2 B ## 7 2010BS40 L567 1 A ## 8 2010BS40 L567 2 A ## 9 2010BS40 L1007 1 A ## 10 2010BS40 L1007 2 B ## # … with 7,624,782 more rows ## # ℹ Use `print(n = ...)` to see more rows 2.2 Kin finding power analysis assuming no physical linkage To assess the power of a set of markers for kin finding, CKMRsim requires the allele freqencies in a particular format. These steps calculate the allele frequencies and format them as required: locus_names &lt;- unique(long_genos$Locus) afreqs_ready &lt;- long_genos %&gt;% count(Locus, Allele) %&gt;% group_by(Locus) %&gt;% mutate( Freq = n / sum(n), Chrom = &quot;Unk&quot;, Pos = as.integer(factor(Locus, levels = locus_names)) ) %&gt;% ungroup() %&gt;% select(Chrom, Pos, Locus, Allele, Freq) %&gt;% arrange(Pos, desc(Freq)) %&gt;% mutate(AlleIdx = NA, LocIdx = NA) %&gt;% filter(!is.na(Allele)) %&gt;% reindex_markers() The allele frequencies look like this: afreqs_ready ## # A tibble: 7,423 × 7 ## Chrom Pos Locus Allele LocIdx AlleIdx Freq ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Unk 1 L252 A 1 1 0.724 ## 2 Unk 1 L252 B 1 2 0.268 ## 3 Unk 1 L252 O 1 3 0.00876 ## 4 Unk 2 L253 A 2 1 0.739 ## 5 Unk 2 L253 B 2 2 0.196 ## 6 Unk 2 L253 O 2 3 0.0654 ## 7 Unk 3 L472 A 3 1 0.570 ## 8 Unk 3 L472 B 3 2 0.422 ## 9 Unk 3 L472 O 3 3 0.00741 ## 10 Unk 4 L567 A 4 1 0.860 ## # … with 7,413 more rows ## # ℹ Use `print(n = ...)` to see more rows These allele frequencies then get compiled into an R object that includes the results of a number of calculations that account for genotyping error and a number of matrices that allow rapid simulation of kin pairs from the data. This takes a little while because it is a fairly large data set. But not more than a minute on my laptop. ckmr &lt;- create_ckmr( D = afreqs_ready, kappa_matrix = kappas[c(&quot;PO&quot;, &quot;FS&quot;, &quot;HS&quot;, &quot;HAN&quot;, &quot;U&quot;), ], ge_mod_assumed = ge_model_TGIE, ge_mod_true = ge_model_TGIE, ge_mod_assumed_pars_list = list(epsilon = 0.005), ge_mod_true_pars_list = list(epsilon = 0.005) ) The kappa_matrix specifies the identify coefficients (the \\(\\kappa\\)’s) for the different relationships we want. The remaining options tell it to use a fairly generic model for genotyping error with an error rate (epsilon) at which we expect about 1% of the genotypes to have a genotyping error. The variable kappas is a piece of package data that looks like this: kappas ## kappa0 kappa1 kappa2 ## MZ 0.0000 0.00000 1.00000 ## PO 0.0000 1.00000 0.00000 ## FS 0.2500 0.50000 0.25000 ## HS 0.5000 0.50000 0.00000 ## GP 0.5000 0.50000 0.00000 ## AN 0.5000 0.50000 0.00000 ## DFC 0.5625 0.37500 0.06250 ## HAN 0.7500 0.25000 0.00000 ## FC 0.7500 0.25000 0.00000 ## HFC 0.8750 0.12500 0.00000 ## DHFC 0.7656 0.21875 0.01562 ## SC 0.9375 0.06250 0.00000 ## HSC 0.9688 0.03125 0.00000 ## U 1.0000 0.00000 0.00000 So, the line kappas[c(&quot;PO&quot;, &quot;FS&quot;, &quot;HS&quot;, &quot;HAN&quot;, &quot;U&quot;), ] is merely picking out the rows from that matrix that we want to focus on: we want to be prepared to do calculations concerning the relationships of: U: unrelated HAN: half aunt-niece (which includes half uncle-niece and half uncle-nephew, etc.) HS: half sibling FS: full sibling PO: parent-offspring Now we can simulate some log likelihood ratios and plot them to see how they look. # This simulates a large number of pairwise genotype probabilites # at each locus Qs &lt;- simulate_Qij( ckmr, calc_relats = c(&quot;PO&quot;, &quot;FS&quot;, &quot;HS&quot;, &quot;HAN&quot;, &quot;U&quot;), sim_relats = c(&quot;PO&quot;, &quot;FS&quot;, &quot;HS&quot;, &quot;HAN&quot;, &quot;U&quot;) ) # In the following, we extract those genotype probabilities in different # ways to calculate a variety of different log-likelihood ratios # for different relationships. # in this particular case, we are looking at log likelihood ratios # for the hypothesis of Parent-Offspring vs Unrelated PO_U_logls &lt;- extract_logls( Qs, numer = c(PO = 1), denom = c(U = 1) ) # And we can plot the distribution of those logl ratios for each # of the different true relationships. ggplot( PO_U_logls, aes(x = logl_ratio, fill = true_relat) ) + geom_density(alpha = 0.25) Clearly, PO and U should be easily resolved. And it turns out that physical linkage does not affect the distribution of log-likelihood ratios when the true relationship is either U or PO (so long as the markers are not in linkage disequilibrium). And we can use importance sampling to estimate false positive rates. mc_sample_simple( Qs, nu = &quot;PO&quot; ) ## # A tibble: 5 × 10 ## FNR FPR se num_non…¹ Lambd…² pstar mc_me…³ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.01 6.30e-193 0 9900 436. PO IS ## 2 0.05 5.96e-200 0 9500 453. PO IS ## 3 0.1 1.00e-203 0 9000 463. PO IS ## 4 0.2 2.41e-208 0 8000 474. PO IS ## 5 0.3 8.47e-212 0 7000 482. PO IS ## # … with 3 more variables: numerator &lt;chr&gt;, ## # denominator &lt;chr&gt;, true_relat &lt;chr&gt;, and ## # abbreviated variable names ¹​num_nonzero_wts, ## # ²​Lambda_star, ³​mc_method ## # ℹ Use `colnames()` to see all variable names The FPR gives that probability of falsely declaring an unrelated pair a parent-offspring pair, for a few different values of the false negative rate. Clearly, there is no chance, whatsoever, of an unrelated pair being mistaken as a PO pair. For all other relationship types, the fact of physical linkage is important. In particular, physical linkage really becomes important when we start to consider kin pairs that are less related than half-siblings, but not a lot less, for example, the HAN, or “half-aunt-niece” category. 2.3 Power for kin-finding while accounting for physical linkage With CKMRsim, we can simulate likelihood ratios (which are calculated without reference to the physical linkage) under the influence of physical linkage, BUT In order to do that formally, we need to know where in the genome all these markers are. We don’t know that, in this case, but we can still get a very good sense for the effect of linkage by imagining that all these markers are spread throughout an appropriately sized genome. Since we are simulating lots of pairs in this way, the exact details of the physical linkage are not quite as important as if we were trying to calculate likelihoods given the linkage. 2.3.1 Make a pseudo genome for these critters A quick search for “bearded seal cytogenetics” leads us to a paper written in 1967 (Fay et al. 1967) which tells us that they have a karyotype of 2n=34. That means they have 16 pairs of autosomes and one pair of sex chromosomes. That is not a huge abundance of chromosomes, but it is not as bad as fruit flies, which have \\(2n = 8\\)—only four pairs of chromosomes. If you look at pictures of the karyotype, the smallest chromosomes are about 1/4 the size of the largest. Here is a screen grab from the the paper: On top of that, a quick web search finds an announcement, not long ago, of completion of a draft genome for bearded seals. From this we find that the genome length is about 2.4 gigabases. Cool. We can use those pieces of information (\\(2n = 34\\), smallest chromosome about 1/4 the size of the largest, and genome length = 2.4 gigabases) to create a pseudo-genome and then sprinkle our markers into it in order to get a sense for how much physical linkage will affect the distribution of the log likelihood ratios. In this process, we will assume a recombination rate of 1 cm per megabase (about a 1 in 100 chance of a recombination occurring within 1 megabase during any meiosis). # this function is part of the CKMRsim package # make fake chromosome lengths fake_chromo_lengths &lt;- geometric_chromo_lengths( n = 16, L = 2.4, sl = 0.25 ) Here is a plot of those simulated chromosome lengths scaled, roughly, to correspond to the sizes of the chromosomes in the figure above, on your screen: fake_chromo_lengths$chrom_length_plot Now that we have that approximate genome to play with, let’s go ahead and randomly place our variants into it. set.seed(5) afreqs_link &lt;- sprinkle_markers_into_genome(afreqs_ready, fake_chromo_lengths$chrom_lengths) Have a look at the output. The original Locus names are there, but each is placed on a chromosome (the fc in fc01 stands for “fake chromosome”). Now we can make a new CKMR object that has these (fake) physical-location data for the markers. ckmr_link &lt;- create_ckmr( D = afreqs_link, kappa_matrix = kappas[c(&quot;PO&quot;, &quot;FS&quot;, &quot;HS&quot;, &quot;HAN&quot;, &quot;U&quot;), ], ge_mod_assumed = ge_model_TGIE, ge_mod_true = ge_model_TGIE, ge_mod_assumed_pars_list = list(epsilon = 0.005), ge_mod_true_pars_list = list(epsilon = 0.005) ) And, now, to simulate with physical linkage, we use the simulate_Qij() function with the unlinked = FALSE option, but we also need to include information about the pedigrees corresponding to each relationship. That information is in the package data object pedigrees. Qs_link_BIG &lt;- simulate_Qij( ckmr_link, calc_relats = c(&quot;PO&quot;, &quot;FS&quot;, &quot;HS&quot;, &quot;HAN&quot;, &quot;U&quot;), sim_relats = c(&quot;PO&quot;, &quot;FS&quot;, &quot;HS&quot;, &quot;HAN&quot;, &quot;U&quot;), unlinked = FALSE, pedigree_list = pedigrees ) Here we plot the densities of the PO/U log likelihood ratio for the different true relationships: # We save the plot so that we can use it # later to compare to our observed values PO_U_gg &lt;- Qs_link_BIG %&gt;% extract_logls(numer = c(PO = 1), denom = c(U = 1)) %&gt;% ggplot(aes(x = logl_ratio, fill = true_relat)) + geom_density(alpha = 0.25) + ggtitle(&quot;PO/U Logl Ratio&quot;) PO_U_gg Aha! When we simulate those likelihood ratios whilst taking account of physical linkage, we see that there is a lot more spread in the distributions, (except for the PO or U relationships, as we mentioned before) and, consequently, a whole lot more overlap. Now, let us look at things when we use other likelihood ratios. For example to distinguish between Full Sibs and Unrelated individuals, we would use the FS/U log-likelihood ratio: FS_U_gg &lt;- Qs_link_BIG %&gt;% extract_logls(numer = c(FS = 1), denom = c(U = 1)) %&gt;% ggplot(aes(x = logl_ratio, fill = true_relat)) + geom_density(alpha = 0.25) + ggtitle(&quot;FS/U Logl Ratio&quot;) FS_U_gg Looking at the FS and U curves there, it is pretty clear that they are very well separated, but, it is also clear that if only this FS/U log-likelihood ratio were used, then POs would be put into the FS category. But don’t despair! If you want to distinguish PO from FS, you should use the PO/FS logl ratio! Here it is for distinguishing between PO and FS: PO_FS_gg &lt;- Qs_link_BIG %&gt;% extract_logls(numer = c(PO = 1), denom = c(FS = 1)) %&gt;% ggplot(aes(x = logl_ratio, fill = true_relat)) + geom_density(alpha = 0.25) + ggtitle(&quot;PO/FS Logl Ratio&quot;) PO_FS_gg Here for the hypothesis of FS versus HS: FS_HS_gg &lt;- Qs_link_BIG %&gt;% extract_logls(numer = c(FS = 1), denom = c(HS = 1)) %&gt;% ggplot(aes(x = logl_ratio, fill = true_relat)) + geom_density(alpha = 0.25) + ggtitle(&quot;FS/HS Logl Ratio&quot;) FS_HS_gg And finally for HS versus HAN: HS_HAN_gg &lt;- Qs_link_BIG %&gt;% extract_logls(numer = c(HS = 1), denom = c(HAN = 1)) %&gt;% ggplot(aes(x = logl_ratio, fill = true_relat)) + geom_density(alpha = 0.25) + ggtitle(&quot;HS/HAN Logl Ratio&quot;) HS_HAN_gg Aha! There is some overlap between HAN and HS, so we will need to keep that in mind, since we don’t want to mistake any HANs for HSs. When using the HS/HAN log-likelihood ratio, we can see how many Unrelated pairs might conceivably get in there. We can use importance sampling when the truth is U, and we can use the distribution of unlinked markers for that (because linkage does not affect the distribution of the log likelihoods in unrelated pairs), and we can use the linked simulations for calculating the False Negative Rates of the half-siblings: mc_sample_simple( Q = Qs, Q_for_fnrs = Qs_link_BIG, nu = &quot;HS&quot;, de = &quot;HAN&quot;, method = &quot;IS&quot; ) ## # A tibble: 5 × 10 ## FNR FPR se num_n…¹ Lambd…² pstar mc_me…³ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.01 1.46e-27 9.86e-28 10000 -10.2 HS IS ## 2 0.05 1.04e-30 8.36e-31 9993 1.05 HS IS ## 3 0.1 4.32e-33 3.55e-33 9962 6.82 HS IS ## 4 0.2 1.57e-38 3.90e-39 9638 13.6 HS IS ## 5 0.3 2.80e-42 8.33e-43 8659 18.6 HS IS ## # … with 3 more variables: numerator &lt;chr&gt;, ## # denominator &lt;chr&gt;, true_relat &lt;chr&gt;, and ## # abbreviated variable names ¹​num_nonzero_wts, ## # ²​Lambda_star, ³​mc_method ## # ℹ Use `colnames()` to see all variable names Good. There is clearly no chance that an unrelated individual would be incorrectly called an HS based on the HS/HAN log-likelihood ratio. But, what about the chance that a HAN will be mistaken for an HS? We can use mc_sample_simple() for this, and we don’t have to do any importance sampling, because there just aren’t that many HAN pairs (relative to the number of U pairs): mc_sample_simple( Q = Qs_link_BIG, nu = &quot;HS&quot;, de = &quot;HAN&quot;, tr = &quot;HAN&quot;, method = &quot;vanilla&quot; ) ## # A tibble: 5 × 8 ## FNR FPR Lambda_s…¹ pstar mc_me…² numer…³ denom…⁴ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.01 0.131 -10.2 NA vanilla HS HAN ## 2 0.05 0.0355 1.05 NA vanilla HS HAN ## 3 0.1 0.016 6.82 NA vanilla HS HAN ## 4 0.2 0.0047 13.6 NA vanilla HS HAN ## 5 0.3 0.0013 18.6 NA vanilla HS HAN ## # … with 1 more variable: true_relat &lt;chr&gt;, and ## # abbreviated variable names ¹​Lambda_star, ## # ²​mc_method, ³​numerator, ⁴​denominator ## # ℹ Use `colnames()` to see all variable names This suggests that if we set a threshold \\(\\Lambda^*_\\mathrm{HS/HAN} = 6.3\\) then we would expect to be missing only about 10% of the true HS pairs, and any HAN pairs would only have a 1.7% chance of having a \\(\\Lambda_\\mathrm{HS/HAN} &gt; \\Lambda^*_\\mathrm{HS/HAN}\\). (Keeping in mind that these are approximations made by sprinkling loci into a pseudo-genome.) Looking at all of these is quite informative. It suggests that the order that we will want to pursue our kin-finding in is: Find all PO pairs by high PO/U and also PO/FS &gt; 0. Once we have the PO pairs, we remove them from futher consideration and identify the FS pairs. For that we will look for pairs with FS/HS above -20 or so. Obviously no unrelateds will be anywhere near that, but we could still check that with the importance sampling. Once we have the PO and FS individuals we will compute the HS/HAN logl_ratios for the remaining pairs and then set the cutoff at what we calculated above, with an FNR of about 10% or 20%. But we will want to investigate the empirical distribution of all those values, too, to see if we can see a HAN bump. 2.4 Doing the pairwise comparisons Because of the ages of these individuals it is probably likely that many of them could not be PO are FS. Many probably would be more likely to be GP than HS, all things being equal, too. Some of these might be AN instead of HS. All those considerations should be taken into account in CKMR. But, for today, since we don’t have the metadata necessary to make those considerations, we will just look for kin pairs amongst all the pairs in the data set. 2.4.1 Make sure we don’t have duplicate samples in here Unless there is a lot of wonky inbreeding going on, it is unlikely that samples that are not the same individual will have close to 100% matching genotypes. Here we find all the pairs that mismatch at 500 or fewer loci out of the 2500 that are in the data set: matchers &lt;- find_close_matching_genotypes( LG = long_genos, CK = ckmr, max_mismatch = 500 ) matchers ## [1] indiv_1 indiv_2 ind1 ind2 ## [5] num_mismatch num_loc ## &lt;0 rows&gt; (or 0-length row.names) There are none. Cool. This might be because Mark Bravington and Paul worked these data over pretty hard before they fell into our hands, and they did this important step already—either that, or these data were sampled and processed by incredibly fastidious people, and/or it is not likely that the same individual is sampled twice. 2.4.2 Using the pairwise_kin_logl_ratios() function To compare each individual’s genotype to every other individual’s genotype to compute the log-likelihood ratios to find kin pairs, we use CKMRsim’s pairwise_kin_logl_ratios() function. The syntax is pretty simple: you pass it two long-format tibbles of genotypes (like long_genos). If the data set passed in each time is the same, the function knows to order the observations and keep only one set of the two comparisons that are made between each unique sample ID in the dataset. You can specify the numerator and the denominator for the log likelihood ratios to be computed. (Also, the function is parallelized, but we don’t use that feature here, because our GitHub actions workflow that renders this document might not use multiple cores.) Below, we wrap the whole thing into an lapply so that we can run the pairwise_kin_logl_ratios() function four times, to get the different logl ratios: PO/U, PO/FS, FS/HS, and HS/HAN, and then present the results in a tidy tibble. 2.4.3 Doing pairwise comparisons somewhat systematically So, we only really have four columns to make: PO/U, PO/FS, FS/HS, and HS/HAN. I am going to make them all and then put them into a big data frame. The number of markers is the same every time. pw_4_LRTs &lt;- lapply( X = list( POU = c(&quot;PO&quot;, &quot;U&quot;), POFS = c(&quot;PO&quot;, &quot;FS&quot;), FSHS = c(&quot;FS&quot;, &quot;HS&quot;), HSHAN = c(&quot;HS&quot;, &quot;HAN&quot;) ), FUN = function(x) { pairwise_kin_logl_ratios( D1 = long_genos, D2 = long_genos, CK = ckmr, numer = x[1], denom = x[2], num_cores = 8 ) } ) %&gt;% bind_rows( .id = &quot;lr_type&quot; ) %&gt;% pivot_wider(names_from = lr_type, values_from = logl_ratio) And now we can see how things compare to our simulations. 2.4.4 Finding the PO pairs First, let’s look at all the pairs that had a PO/U logl &gt; 0. topPO &lt;- pw_4_LRTs %&gt;% arrange(desc(POU)) %&gt;% filter(POU &gt; 0) topPO ## # A tibble: 11 × 7 ## D2_indiv D1_in…¹ num_loc POU POFS FSHS HSHAN ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 EB19GAM0… EB19GA… 2569 472. 83.6 71.1 132. ## 2 EB19GAM0… EB19GA… 2569 468. 87.9 61.5 130. ## 3 EB15GAM0… EB15GA… 2569 452. 72.4 68.0 126. ## 4 EB15GAM0… EB15GA… 2569 396. 80.0 24.9 116. ## 5 EB12PH024 EB19PH… 2569 385. 42.0 33.1 127. ## 6 EB18GAM0… EB18GA… 2569 297. -38.3 35.2 119. ## 7 SAV-004-… SAV-00… 2569 293. -2.02 22.0 105. ## 8 EB17GAM0… EB17GA… 2569 261. 27.8 -23.4 98.1 ## 9 EB13PH031 EB15PH… 2569 256. -11.6 -4.07 105. ## 10 EB12GAM0… EB12GA… 2569 201. -60.4 0.435 100. ## 11 EB15GAM0… EB15GA… 2569 177. -5.98 -48.9 87.4 ## # … with abbreviated variable name ¹​D1_indiv We can plot those pairs against the simulated PO/U logls that we made previously. set.seed(54) # for the jittering PO_U_gg + geom_jitter( data = topPO, mapping = aes(x = POU, y = -0.002, colour = POFS &gt; 0), width = 0, height = 0.001, fill = NA, shape = 21 ) The points below the \\(y=0\\) line are the PO/U logls for those 11 pairs. They are colored green if their PO/FS logl is greater than 0. From this we see 5 pairs that look like solid PO pairs. Those 5, on average have lower PO/U logls than we would have expected from the simulations, which is possibly due to the genotyping error rate in the data being higher than the values that we specified. There is something wonky thing going on with the 6th green point. I thought at first that maybe it was inbred full siblings, but then it would have a higher FSHS. Weird. But, for now, we will call all 6 of those PO pairs, but I would be pretty skeptical about that 6th one. Here we create a table of likely PO pairs: likelyPO &lt;- topPO %&gt;% filter(POFS &gt; 20) 2.4.5 Finding full sibling pairs To do this, we take the remaining pairs and look at their FS/HS logl values, let’s start by taking anything with an FS/HS logl &gt; -20. topFS &lt;- pw_4_LRTs %&gt;% anti_join(likelyPO, by = c(&quot;D2_indiv&quot;, &quot;D1_indiv&quot;)) %&gt;% # remove the PO pairs arrange(desc(FSHS)) %&gt;% filter(FSHS &gt; -20) topFS ## # A tibble: 4 × 7 ## D2_indiv D1_indiv num_loc POU POFS FSHS HSHAN ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 EB18GAM019 EB18GAM… 2569 297. -38.3 35.2 119. ## 2 SAV-004-04 SAV-007… 2569 293. -2.02 22.0 105. ## 3 EB12GAM005 EB12GAM… 2569 201. -60.4 0.435 100. ## 4 EB13PH031 EB15PH0… 2569 256. -11.6 -4.07 105. That is only four individuals. Let’s see where they fall out against the simulated distribution: set.seed(54) # for the jittering FS_HS_gg + geom_jitter( data = topFS, mapping = aes(x = FSHS, y = -0.002), width = 0, height = 0.001, fill = NA, shape = 21 ) So, that is four individuals that look like full siblings (since PO has already been removed). Once again, their FS/HS logl values are trending a little lower than what we expect, which might intimate that our model for the genetic data (genotyping error rates) might not be spot on. But those four individuals still look like full-siblings. 2.4.6 Looking for half-siblings So, finally let’s start looking for half-siblings. remaining &lt;- pw_4_LRTs %&gt;% anti_join(bind_rows(likelyPO, topFS), by = c(&quot;D2_indiv&quot;, &quot;D1_indiv&quot;)) We can have a look at the bumps we might see on the extreme right end of the unrelated distribution and then the others. all_HSHAN_logsl &lt;- ggplot(remaining, aes(x = HSHAN)) + geom_histogram(bins = 30) Plot all of them: all_HSHAN_logsl + ggtitle(&quot;All Remaining Pairs&quot;) So, the HSHAN logls of almost all of the remaining pairs are quite low. But, let us have a look at the extreme right edge there: all_HSHAN_logsl + xlim(-45, NA) + ggtitle(&quot;Pairs with HSHAN &gt; -45&quot;) ## Warning: Removed 1100179 rows containing non-finite values ## (stat_bin). ## Warning: Removed 1 rows containing missing values ## (geom_bar). Aha! There are probably some half-sibling pairs. There are also probably some half-aunt-niece pairs in there. Let’s look at all of those as points. set.seed(52) HS_HAN_gg + geom_jitter( data = remaining %&gt;% filter(HSHAN &gt; -65), mapping = aes(x = HSHAN, y = -0.02), width = 0, height = 0.01, fill = NA, shape = 21 ) + coord_cartesian(xlim = c(-65, 125), ylim = c(NA, 0.04)) Ooh! That is a pretty neat way to look at it. With over roughly a million unrelated pairs, in total, we see that quite a few of them are on the far right edge of the distribution for the unrelated pairs. Then a smattering of individuals in the HAN region, and then a sizable break after \\(x=0\\) till a cluster of points that are right in the middle of what is expected for half siblings. Finally there is one individual way to the right, that is not really where you would expect a half-sibling to sit. We can look at all of those, and we find 18 likely half-sibs, and one that is probably a PO pair, but may involve some inbreeding: remaining %&gt;% filter(HSHAN &gt; 0) %&gt;% arrange(HSHAN) %&gt;% as_data_frame() ## Warning: `as_data_frame()` was deprecated in tibble 2.0.0. ## ℹ Please use `as_tibble()` instead. ## ℹ The signature and semantics have changed, see ## `?as_tibble`. ## # A tibble: 19 × 7 ## D2_indiv D1_in…¹ num_loc POU POFS FSHS HSHAN ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 EB12GAM0… EB14GA… 2569 -309. -221. -161. 9.14 ## 2 EB16GAM0… EB17GA… 2569 -341. -253. -172. 11.3 ## 3 EB13GAM0… EB16PH… 2569 -395. -326. -155. 13.2 ## 4 EB15GAM0… EB15GA… 2569 -321. -251. -155. 14.7 ## 5 EB17PH043 SH-G19… 2569 -412. -346. -160. 15.7 ## 6 EB17PH037 SH-S26… 2569 -450. -393. -151. 16.8 ## 7 EB20GAM0… SH-055… 2569 -294. -241. -139. 17.0 ## 8 2011BS25 EB10PH… 2569 -351. -290. -151. 17.1 ## 9 DIO-036-… EB12SH… 2569 -301. -230. -164. 18.7 ## 10 EB10DIO0… UNK11G… 2569 -314. -251. -156. 19.5 ## 11 SH-S04-05 SH-S15… 2569 -286. -231. -144. 19.5 ## 12 EB09GAM0… EB17GA… 2569 -238. -196. -132. 20.7 ## 13 EB08NOM0… EB09SH… 2569 -311. -268. -140. 21.4 ## 14 EB05KVL0… EB11PH… 2569 -283. -238. -142. 21.7 ## 15 EB13GAM0… EB19GA… 2569 -325. -270. -163. 24.1 ## 16 2011BS7 EB06PH… 2569 -314. -281. -141. 25.0 ## 17 2012BS13 EB09SH… 2569 -212. -192. -135. 30.8 ## 18 EB12PH022 EB16PH… 2569 -324. -360. -101. 36.9 ## 19 EB15GAM0… EB15GA… 2569 177. -5.98 -48.9 87.4 ## # … with abbreviated variable name ¹​D1_indiv Once we have done this initial round of kin-finding, we would typically go back and check it with the meta data. Keeping in mind that individuals in the HS categories could be grandparent-grandchild, or, much less likely, full-aunt-niece. 2.5 Check the distribution of all pairs against the simulated unrelated pairs Because an overwhelming majority of the pairs should be (largely) unrelated, the observed distribution of logls from all pairs should be close to what is simulated for unrelated individuals. We can plot the densities and compare Here we do it for the \\(\\Lambda_{PO/U}\\). The red-filled density is the simulated (theoretical) curve, and the unfilled black line is what was observed. simU_POU &lt;- Qs %&gt;% extract_logls(numer = c(PO = 1), denom = c(U = 1)) %&gt;% filter(true_relat == &quot;U&quot;) ggplot() + geom_density( data = simU_POU, mapping = aes(x = logl_ratio), fill = &quot;red&quot;, alpha = 0.3 ) + geom_density( data = pw_4_LRTs, mapping = aes(x = POU) ) Whoa! That is somewhat unexpected. We expect to have a little bump in the observed curve on the right hand side, because there should be some pairs that are not completely unrelated. But the long tail to the left is a hard one to explain. That fat tail on the left in the observed distribution remains, even for a likelihood ratio that should not be too affected by the genotyping error model (\\(\\Lambda_{HS/HAN}\\)): simU_HSHAN &lt;- Qs %&gt;% extract_logls(numer = c(HS = 1), denom = c(HAN = 1)) %&gt;% filter(true_relat == &quot;U&quot;) ggplot() + geom_density( data = simU_HSHAN, mapping = aes(x = logl_ratio), fill = &quot;red&quot;, alpha = 0.3 ) + geom_density( data = pw_4_LRTs, mapping = aes(x = HSHAN) ) This is interesting. As a population geneticist I would want to follow up on this to figure out what feature of our genetic data or of the population under study is leading to this distortion from what we expect. There might be an interesting story there! 2.6 Conclusion One big take-home message here is that it takes a lot of good genetic markers to be able to reliably distinguish half-siblings from half-aunt niece relationships. This is a tremendously robust data set, and the distinction between those groups seems reasonably clear, but with fewer markers it would be a lot harder. Don’t sell yourself short on the genetic markers!! References Fay FH, Rausch VR, Feltz ET (1967) Cytogenetic comparison of some pinnipeds (mammalia: eutheria). Canadian Journal of Zoology, 45, 773–778. "],["simulation-and-inference-play-with-hillary-et-al.s-white-shark-ckmr-example.html", "Session 3 Simulation and Inference Play with Hillary et al.’s White Shark CKMR example 3.1 Simulating from the inferential model 3.2 An R function to compute the negative log-likelihood 3.3 Evaluate the likelihood with TMB 3.4 Visualize those log likelihood values 3.5 Minimizing the negative log likelihood 3.6 Sampling from the Posterior with ‘tmbstan’ 3.7 Summary", " Session 3 Simulation and Inference Play with Hillary et al.’s White Shark CKMR example Here we explore the models used in Hillary et al. (2018) to estimate abundance of white sharks in Australia. Looking through the paper, I didn’t find any direct mention of a public repository of data that was used in the paper, nor any repository of code for their analyses. So, we are just going to simulate some data here to play with. While it would be customary to simulate data from a full, age-structured demographic model, we are, instead, going to simulate kin-pair data from the model that they use for inference. One nice thing about simulating from their inference model is that doing so offers a good way to gain a better understanding of that inference model. In a later session we will confront data simulated from a forward-in-time, age-structured population simulation. The main goal of this session is to explore the properties of a simple inference model for CKMR, and also to become familiar with the ‘TMB’ and ‘tmbstan’ R packages. We will start off by loading the R packages that we need for this session. library(tidyverse) library(microbenchmark) library(TMB) library(tmbstan) library(shinystan) 3.1 Simulating from the inferential model 3.1.1 Exponential growth model The authors start with an exponential growth (or decline) model for the number of adults: \\[ N_t^A = N_0^Ae^{\\lambda t} \\] where \\(N_t^A\\) is the number of adults at time \\(t\\) and \\(N_0^A\\) is the initial number of adults (at time \\(t = 0\\)). \\(\\lambda\\) is an exponential growth rate. In practice, time is often translated so that \\(t = 0\\) corresponds to the birth year of the oldest second-born member of a pair in the data set. Here, we define a function to calculate \\(N_t^A\\): #&#39; calculate the number of adults at time t, given exponential growth or decline #&#39; @param N0 number of adults at time 0 #&#39; @param t time #&#39; @param lambda exponential growth rate parameter N_adults &lt;- function(N0, t, lambda) { N0 * exp(lambda * t) } Let’s see what that would look like over 60 years, starting from a few different \\(N_0\\) values and growing/shrinking at a range of values. A_traj &lt;- expand_grid( Ninit = c(600, 800, 1000, 1200, 1500, 2000), lambda = seq(-0.03, 0.03, by = 0.01) )%&gt;% mutate( num_adults = map2(Ninit, lambda, function(x, y) N_adults(x, 0:60, y)), ) %&gt;% unnest(num_adults) %&gt;% group_by(Ninit, lambda) %&gt;% mutate(year = 0:60) ggplot(A_traj, aes(x = year, y = num_adults, colour = factor(lambda))) + geom_line() + facet_wrap(~ Ninit) 3.1.2 Model for kin pairs We imagine that \\(n\\) young (ages 3 to 8) sharks get sampled each year, and we will assume that they can be accurately aged. So, for each sampled individual, we know its age. To make CKMR inference we will investigate the kin-pair relationship (if any) of each pair of samples, focusing on half-sibling pairs. In order to minimize the effect of correlated survival of individuals in shared environments, we will restrict our attention only to pairs of individuals that were born in different years. In doing CKMR it is helpful to order each pair of samples by age, so that each pair includes a first-born member and a second-born member. We will be using the terms “first-born” and “second-born” a lot to describe these two members of each pair. For the purposes of CKMR, here, the most important feature/covariate of each individual is the year that it was born. We will denote this by \\(c_1\\) and \\(c_2\\) (think \\(c\\) for cohort) for the first-born and second-born of each pair, respectively. We further assume that there is an equal sex ratio amongst the adults, so that, if there are \\(N^A_t\\) adults at time \\(t\\), that means there are \\(N^A_t/2\\) adult males and \\(N^A_t/2\\) adult females at time \\(t\\). To formulate a CKMR pseudo-likelihood using half-sibling pairs (as was done by Hillary et al. (2018)) requires that we derive the probability that a pair of samples with birth years \\(c_1\\) and \\(c_2\\) are half-siblings. A pair can be half-siblings either through their mother (maternal half siblings) or through their father (paternal half siblings). These events are disjoint (though not necessarily independent—in strictly monogamous species every paternal half sibling is a maternal half sibling, because every sibling is a full sibling), so they can be thought of as separate “chances” to be a half sibling. We assume that the probability of full-siblings born in different years in these sharks is very small, and we treat the maternal and paternal “chances” to be half-siblings as independent. In order for a pair to be maternal half siblings here is what must happen: A particular female must give birth to the first-born at time \\(c_1\\). This happens with probability 1, because every individual has a mother. That particular female must survive from year \\(c_1\\) to year \\(c_2\\) so that it could be a part of the \\(N_{c_2}^A/2\\) females that were available to give birth to the second-born. Given that the female survived, the probability that she is the one female amongst the \\(N_{c_2}^A/2\\) females available to produce offspring born in year \\(c_2\\) is \\(\\frac{1}{N_{c_2}^A/2} = 2/N_{c_2}^A\\). It is worth noting that in the Hillary et al. (2018) formulation, (3) has the probability that it does because it is assumed that every adult female shark has the same expected relative reproductive output. This is reasonable for sharks whose fecundity does not depend greatly on body size. It becomes more challenging in cases where fecundity varies with size or age of the fish, because, in that case, if the first-born was born to a large, old female that survives to year \\(c_2\\), then, since that large female will produce proportionally more offspring at \\(c_2\\), the probability of the pair being half-siblings is higher than if they were born to a young/small female. (This is further complicated by the fact that the age of the parent of each sample is not typically knowable.) Also apparent from the above formulation in (2) is that we have to be able to calculate the probability that a female survives from year \\(c_1\\) to \\(c_2\\). This requires that we include in our model an annual adult survival rate. In the case of Hillary et al. (2018), this applies to both adult males and adult females and we will denote it by \\(\\phi_A\\). So the probability that an adult survives from year \\(c_1\\) to year \\(c_2\\) is \\(\\phi_A^{c_2 - c_1}\\). From the foregoing, we can derive that the probability that a pair of samples are maternal half-siblings, given the model in Hillary et al. (2018) is: \\[ \\phi_A^{c_2 - c_1}\\frac{2}{N^A_{c_2}}. \\] It is worth looking at that and keeping in mind that the part that depends on the population size always depends on the number of adults at the time of the second-born’s birth, and not at the time of the first-born’s birth. The foregoing were the calculations for being maternal half siblings, but each pair also has a separate (and identical, in the model of Hillary et al. (2018)) chance of being paternal half siblings. Since the events of being a maternal half sibling and paternal half sibling are disjoint, and because we assume that the probability of finding a full-sibling pair born in different years, is just the product of the probabilities of finding a maternal half-sibling pair and a paternal half-sibling pair (this is reasonable, by the way—white sharks do not pair bond, as far as we know…) we can add the maternal and paternal half-sibling probabilities together to get the overall probability that a pair is a half-sibling pair: \\[ P(\\mathrm{HSP} | c_1, c_2) = \\phi_A^{c_2 - c_1}\\frac{4}{N^A_{c_2}}. \\] 3.1.3 Simulating from the model for kin pairs Now we are going to write a function to simulate sampled pairs from such a population, and then we will simulate some of them to be half-siblings according to the probabilities in their inferential model. We simulate npy samples from years Slo to Shi inclusive. We simulate the age of each sample by randomly drawing from a vector of weights for each age, and then we form all pairs of samples and, for each pair, calculate the probability that it is an HSP or not. Then, from that probability, we simulate whether or not it is an HSP. #&#39; simulate sampling n sharks a year from year Slo to Shi and return all the sample pairs #&#39; @param npy number of sharks to sample each year (num per year) #&#39; @param Slo year to start sampling #&#39; @param Shi final year in which to sample #&#39; @param ages a vector of the ages at which individuals are sampled #&#39; @param age_wts vector of expected proportion of each age in the sample #&#39; @param N0 initial population size #&#39; @param lambda population growth rate #&#39; @param Thi final time to simulate an abundance (must be &gt;= than Shi) #&#39; @param phiA Adult annual survival probability #&#39; @return This returns a list of three components: `pairs`: a tibble of all the pairs, #&#39; `pair_counts`: a tibble of counts of different pair types of different age differences, #&#39; and `samples`: a simple tibble of just the samples, and `N`: a tibble of the #&#39; number of adults each year. simulate_pairs &lt;- function( npy = 10, Slo = 20, Shi = 40, ages = 3:8, age_wts = rep(1, length(ages)), N0 = 800, lambda = 0.01, Thi = 60, phiA = 0.94 ) { # get the number of adults each year A_traj &lt;- tibble( year = 0:Thi ) %&gt;% mutate( num_adults = N_adults(N0, year, lambda) ) # sample npy individuals each year from Slo to Shi, and assign an age # to each. From that age and the sampling year, calculate the year it # was born in. Then join on for each sample, the number of adults present # at the time it was born. samples &lt;- tibble( samp_year = rep(Slo:Shi, each=npy) ) %&gt;% mutate( age = sample(ages, size = n(), replace = TRUE, prob = age_wts), born_year = samp_year - age ) %&gt;% left_join(A_traj, by = c(&quot;born_year&quot; = &quot;year&quot;)) # now we form all the possible pairs of those samples n &lt;- nrow(samples) s1 &lt;- samples[rep(1:n, each = n),] s2 &lt;- samples[rep(1:n, times = n),] names(s2) &lt;- paste0(names(s2), &quot;.old&quot;) # and we keep only the pairs that were born in different years, and we # enforce an ordering such that the first-born is the &quot;old&quot; one that # was born in born_year.old (i.e. c1) and the younger one was born in # born_year (i.e. c2) pairs &lt;- bind_cols(s1, s2) %&gt;% filter(born_year.old &lt; born_year) %&gt;% mutate( # here we simulate whether each pair is an HSP or not by simulating # a Bernoulli random variable for each pair with success probability # of P(HSP | c1, c2). age_diff = born_year - born_year.old, HSP_prob = (4/num_adults) * (phiA ^ (born_year - born_year.old)), isHSP = rbernoulli(n(), p = HSP_prob) ) # As is often done in CKMR, we can summarize the kin pair data by # counting up the number of kin pairs and non-kin pairs in each category # defined by different sets of covariates. In this case different c1 and # c2, though it is defined here in terms of c2 and the age difference. pair_counts &lt;- pairs %&gt;% count(born_year, age_diff, HSP_prob, isHSP) %&gt;% pivot_wider(names_from = isHSP, values_from = n, values_fill = 0L) %&gt;% rename(n_UP = `FALSE`, n_HSP = `TRUE`) list( N = A_traj, samples = samples, pairs = pairs, pair_counts = pair_counts, pair_data = pair_counts %&gt;% select(-HSP_prob) ) } Now that we have done that, let’s simulate some pairs. We will assume that 20 sharks were sampled per year—that is more than Hillary et al. (2018) had, I think, but it makes the likelihood surface a little cleaner, so, since we can simulate whatever we want, we will simulate an abundance of data: set.seed(5) sim_vals &lt;- simulate_pairs(npy = 20, age_wts = 8:3) Take a moment to look at the output. See that it is a list of tibbles. The first three are: N: the population sizes over time, samples: the ages and sampling years of the samples (also it has the number of adults present at the birth year of each sample) pairs: a tibble with one row for each pair, with the HSP probs calculated, and the simulated Bernoulli random variable in isHSP saying whether it is a kin pair or not. The remaining two elements of the list, sim_vals, are the pair_counts which show the number of half-sibling pairs of different types, and also shows the half-sibling pair probability that was used to simulate them: sim_vals$pair_counts ## # A tibble: 325 × 5 ## born_year age_diff HSP_prob n_UP n_HSP ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 13 1 0.00413 10 0 ## 2 14 1 0.00409 35 0 ## 3 14 2 0.00384 14 0 ## 4 15 1 0.00405 84 0 ## 5 15 2 0.00380 60 0 ## 6 15 3 0.00357 24 0 ## 7 16 1 0.00401 216 0 ## 8 16 2 0.00376 124 2 ## 9 16 3 0.00354 90 0 ## 10 16 4 0.00333 36 0 ## # … with 315 more rows ## # ℹ Use `print(n = ...)` to see more rows In this tibble, n_HSP is the number of half-sibling pairs found in which the second-born was born in born_year (i.e. born_year = \\(c_2\\) ) and the older member was born age_diff years before (i.e. \\(c_1\\) is \\(c_2\\) - age_diff). As you can see, there are a lot of categories for which no HSPs are found. That is to be expected—they are pretty rare, and, of course, you expect to see fewer of them if the population is large…that is how CKMR works… The HSP_prob column gives the probability of seeing an HSP of a certain category given the values of the parameters that were used to simulate the data. Typically if you had some observed data, you wouldn’t compute the HSP_prob for parameter values you didn’t know. So, if you had observed data it would look like: sim_vals$pair_data ## # A tibble: 325 × 4 ## born_year age_diff n_UP n_HSP ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 13 1 10 0 ## 2 14 1 35 0 ## 3 14 2 14 0 ## 4 15 1 84 0 ## 5 15 2 60 0 ## 6 15 3 24 0 ## 7 16 1 216 0 ## 8 16 2 124 2 ## 9 16 3 90 0 ## 10 16 4 36 0 ## # … with 315 more rows ## # ℹ Use `print(n = ...)` to see more rows And the goal from those data would be to estimate the parameters that might have produced these data. That is what we will be doing shortly, but before that, it is worthwhile to plot the half-sibling pair probabilities, just to look at those. sim_vals$pairs %&gt;% group_by(born_year, age_diff) %&gt;% summarise(HSP_prob = mean(HSP_prob)) %&gt;% ggplot(aes(x = born_year, y = HSP_prob, fill = factor(age_diff))) + geom_point(shape = 21) + xlab(&quot;c_2: the birth year of the second-born&quot;) + ylab(&quot;Half-sibling probability&quot;) + guides(fill=guide_legend(title=&quot;age difference,\\n c2 - c1&quot;)) ## `summarise()` has grouped output by &#39;born_year&#39;. You ## can override using the `.groups` argument. Questions: Why do the half-sibling probabilities decline with \\(c_2\\) for any given age difference between the members of the pair? For a given value of \\(c_2\\), why do the half-sibling probabilities decline with increasing age difference? 3.2 An R function to compute the negative log-likelihood To estimate the parameters that gave rise to the simulated data, we can start with an R function to compute the negative log-likelihood—in other words, the probability of our observed data given values of the parameters, which are: the initial number of adults \\(N^A_0\\), the adult population growth rate \\(\\lambda\\), the probability that an adult survives for a year, \\(\\phi_A\\). The following R function computes that CKMR pseudolikelihood from the pair_counts tibble in the output from simulate_pairs. Basically, for each category, defined by born_year (\\(c_2\\)) and an age_diff (such that \\(c_1 = c_2 - \\mathrm{age\\_diff}\\)), the number of half-sibling pairs is a Binomial random variable with number of trials equal to the total number of pairs in that category, and success probability equal to \\(P(\\mathrm{HSP}|c_1, c_2)\\). Just for a little review, a Binomial variable with \\(n\\) trials and success probability \\(p\\) has probability mass function: \\[ P(x|n,p) = {n \\choose x} p^x (1-p)^{n-x}. \\] The binomial coefficient is a constant with respect to \\(p\\), so is not relevant to the likelihood for \\(p\\), so we can write: \\[ P(x|n,p) \\propto p^x (1-p)^{n-x}. \\] And if we wanted to write that as a log likelihood, we would have \\[ \\mathcal{L}(p) = x\\log p + (n-x)\\log(1 - p) \\] You will see that in the logl = line in the function below. #&#39; Return the negative log likelihood of the parameter values given the data #&#39; @param pars a vector (N0, lambda, phiA) #&#39; @param X a tibble like the pair_counts component of the output list from #&#39; `simulate_pairs()`. hsp_nll &lt;- function(pars, X) { N0 &lt;- pars[1] L &lt;- pars[2] # lambda P &lt;- pars[3] # phi LL &lt;- X %&gt;% mutate( N = N0 * exp(L * born_year), # number of adults at time of second-born&#39;s birth hspp = (4 / N) * P ^ age_diff, # P(HSP | c_1, c_2) logl = log(hspp) * n_HSP + log(1 - hspp) * n_UP # log Binomial probability ) -sum(LL$logl) # negative log likelihood } Let’s first compute the negative log-likelihood for the values used in the simulation: hsp_nll( pars = c(800, 0.01, 0.94), X = sim_vals$pair_data ) ## [1] 1508 Since this is a negative log likelihood, a smaller number is better. We can see that if we choose parameter values that are far from the true ones we get a bigger (less good) value of the negative log likelihood. hsp_nll( pars = c(1800, 0.05, 0.94), X = sim_vals$pair_data ) ## [1] 1752 It is a fun exercise to visualize this log-likelihood surface. But we are not going to do that with this hsp_nll function, because it is quite slow. Observe how many milliseconds it takes to evaluate the likelihood using the hsp_nll() function: mb &lt;- microbenchmark::microbenchmark( R_version = hsp_nll( pars = c(1800, 0.05, 0.94), X = sim_vals$pair_data ), times = 1000 ) # on average, typically more than 2 milliseconds: mb ## Unit: milliseconds ## expr min lq mean median uq max neval ## R_version 2.539 2.652 3.22 2.709 2.797 55.81 1000 In general, straight-up R is a little underpowered for computing these sorts of likelihoods (because when doing inference from them, you may need to calculate the likelihood many times) and there are some serious advantages to calculating them in compiled code using the package TMB. We will do that next. 3.3 Evaluate the likelihood with TMB ‘TMB’ is a package that allows you to write a negative log-likelihood in compiled C++ code. Compiled code can be orders of magnitude faster than interpreted R code. Additionally, ‘TMB’ is designed so that if you define a negative log likelihood in compiled code for it, it will also write and compile the code to compute the first and second derivatives of this negative log likelihood. This is called “automatic differentiation” and is quite useful. It relies on the fact that differentiation is fairly straightforward. For example, if you had a little bit of C++ code that defined a function f of x like: f = pow(x, 3) + 3 * pow(x, 2) + 8 * x where pow(x, n) is \\(x^n\\), then it is pretty easy to see that the code for the first derivative of that, with respect to x, would be: df_dx = 3 * pow(x, 2) + 6 * x + 8 And, the second derivative would be something like: d2f_dx2 = 6 * x + 6 ‘TMB’ uses a library called CppAD to be able to take derivatives of very complex functions written in C++, even if those functions are defined with for loops, or even if they, themselves, call other functions. As a consequence it has some pecularities that must be respected. The most notable is that any variable that might be involved in the derivative of the function must be defined as a variable of type Type. We will see what this means as we go through the code. The following code is stored in a file TMB/hsp_nll.cpp inside this repository. // simple half-sibling CKMR with exponential pop growth and known ages #include &lt;TMB.hpp&gt; template&lt;class Type&gt; Type objective_function&lt;Type&gt;::operator() () { DATA_VECTOR(n_UP); DATA_VECTOR(n_HSP); DATA_VECTOR(born_year); DATA_VECTOR(age_diff); PARAMETER(N_init); PARAMETER(lambda); PARAMETER(phiA); ADREPORT(N_init); ADREPORT(lambda); ADREPORT(phiA); Type N; // for storing the pop size at the time of the birth of the second-born Type hsp; // for storing the half-sibling pair prob Type nll = 0; for(int i=0;i&lt;n_UP.size(); i++) { N = N_init * exp(lambda * born_year[i]); hsp = (4 / N) * pow(phiA, age_diff[i]); nll -= log(hsp) * n_HSP[i] + log(1 - hsp) * n_UP[i]; } return nll; } 3.3.1 The general form of a TMB C++ file Any time that you define a negative log likelihood function in compiled code for TMB, it will look something like this. There is always some boilerplate that loads the TMB C++ libraries, and there must be one function called objective_function that returns the objective function that you typically will wish to minimize: #include &lt;TMB.hpp&gt; template&lt;class Type&gt; Type objective_function&lt;Type&gt;::operator() () {... Note that you can also define other functions that you can then call from inside the objective_function. These also must be specified as type Type. We will see that in Paul’s bearded seal example. Then you tell TMB that there will be some data passed to it from R. In our case we are passing in some vectors of data that are defined with these macros. The data are considered “fixed”—i.e. they are the what you have observed. DATA_VECTOR(n_UP); DATA_VECTOR(n_HSP); DATA_VECTOR(born_year); DATA_VECTOR(age_diff); After that we define some variables that are parameters. These are the things that we will wish to estimate, and these are also the variables with respect to which TMB will calculate the derivatives using automatic differentiation. PARAMETER(N_init); PARAMETER(lambda); PARAMETER(phiA); Each one of those is a scalar. N_init here is \\(N_0\\). After that we tell TMB which of the parameters we want TMB to send information back to R about, including information about its derivatives. ADREPORT(N_init); ADREPORT(lambda); ADREPORT(phiA); This is typically used to obtain point estimate and standard deviations of these parameters via the R function sdreport(). Then we start getting into the code itself. Here, when we define intermediate variables that are part of the function that we want to auto-differentiate, we cannot simply define them as standard types like double or integer, but we must define them as type Type: Type N; // for storing the pop size at the time of the birth of the second-born Type hsp; // for storing the half-sibling pair prob Type nll = 0; All that remains is calculating and returning the objective function. In our case it is a negative log likelihood that we store in a variable called nll: for(int i=0;i&lt;n_UP.size(); i++) { N = N_init * exp(lambda * born_year[i]); hsp = (4 / N) * pow(phiA, age_diff[i]); nll -= log(hsp) * n_HSP[i] + log(1 - hsp) * n_UP[i]; } return nll; That’s it for this little example! There are a number of other useful TMB macros that can be used in C++ code, and we will see some of those later. 3.3.2 Compiling and linking TMB C++ code In order to use the code in the C++ file, we have to compile it: compile(&quot;TMB/hsp_nll.cpp&quot;) ## [1] 0 And then, in order to get our data into that function we defined using TMB, we need to make a list with names that are like those in the DATA_VECTOR() parts of the C++ code: # get our data in a list of vectors data &lt;- sim_vals$pair_data %&gt;% select(n_UP, n_HSP, born_year, age_diff) %&gt;% as.list() Finally, we can make a list of starting parameter values with names like those in the PARAMETER() macros of the C++ code: # our starting parameters parameters &lt;- list(N_init = 1000, lambda = 0.001, phiA = 0.9) Finally, in order to make an AD function (this is a function that can evaluate the objective function and also return its derivatives) with TMB, we need to link to the library created when we compiled the file above. For unknown reasons, on a Mac, the ‘TMB’ package seems unable to deal with having the compiled object files in a subdirectory, so, in the following code chunk we test to see if we are on a Mac, and, if we are, we momentarily switch to the TMB directory. Otherwise we just run the functions the way we should be able to. Additionally, at least on a Mac, R seems to do a poor job of realizing whether the compiled library has changed since it last loaded it, so that if you are editing and recompiling your C++ code, then you need to unload it before loading it again. So, I tend to always structure my TMB library-loading code on a Mac like what you see in the first part of the if block, below: if(Sys.info()[&quot;sysname&quot;] == &quot;Darwin&quot;) { setwd(&quot;TMB&quot;) try(dyn.unload(dynlib(&#39;hsp_nll&#39;)), silent = TRUE) dyn.load(dynlib(&#39;hsp_nll&#39;)) obj &lt;- TMB::MakeADFun(data = data, parameters = parameters, DLL=&quot;hsp_nll&quot;) setwd(&quot;..&quot;) } else { dyn.load(dynlib(&quot;TMB/hsp_nll&quot;)) obj &lt;- TMB::MakeADFun(data = data, parameters = parameters, DLL=&quot;hsp_nll&quot;) } Now, the AD function/object from TMB is called obj. We might want to see how long it takes for this compiled version of the HSP negative log likelihood to be computed: mb2 &lt;- microbenchmark( TMB_version = obj$fn(x = parameters), times = 1000 ) mb2 ## Unit: microseconds ## expr min lq mean median uq max ## TMB_version 32.14 32.92 34.07 33.25 33.83 177.6 ## neval ## 1000 Question: How many times faster, on average, is it to evaluate the negative log likelihood in compiled code than when using the version we wrote in R? 3.4 Visualize those log likelihood values Now that we have a fast way to evaluate these negative log likelihoods using TMB, let’s evaluate a lot of them so we can make some contour plots. We will evaluate the log likelihood over a range of values of the three parameters: LL_tib &lt;- expand_grid( N_init = seq(200, 2000, by = 20), lambda = seq(-0.04, 0.04, by = 0.01), phiA = seq(0.85, 1, by = 0.01) ) %&gt;% mutate(parameters = pmap( .l = list(a = N_init, b = lambda, c= phiA), .f = function(a,b,c) list(N_init = a, lambda = b, phiA = c) )) %&gt;% mutate( nll = map_dbl( .x = parameters, .f = function(y) obj$fn(x = y) ) ) The output looks like this: LL_tib ## # A tibble: 13,104 × 5 ## N_init lambda phiA parameters nll ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt; &lt;dbl&gt; ## 1 200 -0.04 0.85 &lt;named list [3]&gt; 2818. ## 2 200 -0.04 0.86 &lt;named list [3]&gt; 2921. ## 3 200 -0.04 0.87 &lt;named list [3]&gt; 3034. ## 4 200 -0.04 0.88 &lt;named list [3]&gt; 3158. ## 5 200 -0.04 0.89 &lt;named list [3]&gt; 3295. ## 6 200 -0.04 0.9 &lt;named list [3]&gt; 3446. ## 7 200 -0.04 0.91 &lt;named list [3]&gt; 3613. ## 8 200 -0.04 0.92 &lt;named list [3]&gt; 3797. ## 9 200 -0.04 0.93 &lt;named list [3]&gt; 4000. ## 10 200 -0.04 0.94 &lt;named list [3]&gt; 4226. ## # … with 13,094 more rows ## # ℹ Use `print(n = ...)` to see more rows With all those results, we can make a contour plot, faceted over values of \\(\\lambda\\) to visualize the negative log-likelihood surface: LL_tib %&gt;% group_by(lambda) %&gt;% mutate(nll = ifelse(nll &gt; min(nll) + 20, NA, nll)) %&gt;% ungroup() %&gt;% ggplot(aes(x = N_init, y = phiA, z = nll)) + geom_contour(binwidth = 1, colour = &quot;gray&quot;) + theme(legend.position = &quot;none&quot;) + facet_wrap(~lambda) + theme_bw() + geom_vline(xintercept = 800, colour = &quot;blue&quot;) + geom_hline(yintercept = 0.94, colour = &quot;red&quot;) ## Warning: Removed 9477 rows containing non-finite values ## (stat_contour). I am sure there is a cleaner way of dropping all the contour lines smaller than a certain value, that doesn’t give us the blocky edge, but I am not going to bother with it here. The blue and red lines show where the actual “true” simulated values of \\(N_\\mathrm{init}\\) and \\(\\phi_A\\) are, respectively. Recall that the true value of \\(\\lambda\\) is 0.01. And see on that facet that the true values of \\(N_\\mathrm{init}\\) and \\(\\phi_A\\) are near the top of the likelihood (or the bottom of the negative log likelihood, if you prefer to think of it that way). We see that with this much data, and whilst assuming the correct growth rate, it appears that the abundance and the adult survival would be estimated quite accurately. The question remains, however, of how much information there is about \\(\\lambda\\). Can we estimate that well? 3.5 Minimizing the negative log likelihood The standard way to minimize the negative log likelihood is to hand of the objective function to one of R’s standard optimizers. The nlminb() function seems to work well. We give it some starting values, the objective function, and its first and second derivates (the gradient and Hessian, respectively). We will try it with the starting values in parameters: nlm_min &lt;- nlminb( start = parameters, objective = obj$fn, gradient = obj$gr, hessian = obj$he ) ## outer mgc: 1472 ## outer mgc: 312.3 ## outer mgc: 8.777 ## outer mgc: 0.007972 ## outer mgc: 23.4 ## outer mgc: 28.16 ## outer mgc: 34.69 ## outer mgc: 0.6566 ## outer mgc: 0.01179 ## outer mgc: 1.222e-08 And here is the result: nlm_min ## $par ## N_init lambda phiA ## 7.365e+02 7.829e-03 9.258e-01 ## ## $objective ## [1] 1507 ## ## $convergence ## [1] 0 ## ## $iterations ## [1] 9 ## ## $evaluations ## function gradient ## 17 10 ## ## $message ## [1] &quot;relative convergence (4)&quot; That is pretty close to the true values that we simulated the data at: \\(N_0 = 800\\), \\(\\lambda = 0.01\\), \\(\\phi_A = 0.94\\). Exercise: Repeat the optimization starting from different values of the parameters and ensure that you get the same maximum likelihood values. Just for fun, let’s look at those points on the likelihood surface. # evaluate at a lot of points to get the surface LL_tib2 &lt;- expand_grid( N_init = seq(200, 2000, by = 20), lambda = 0.007829, phiA = seq(0.85, 1, by = 0.01) ) %&gt;% mutate(parameters = pmap( .l = list(a = N_init, b = lambda, c= phiA), .f = function(a,b,c) list(N_init = a, lambda = b, phiA = c) )) %&gt;% mutate( nll = map_dbl( .x = parameters, .f = function(y) obj$fn(x = y) ) ) ggplot(LL_tib2, aes(x = N_init, y = phiA, z = nll)) + geom_contour(binwidth = 1, colour = &quot;gray&quot;) + theme(legend.position = &quot;none&quot;) + facet_wrap(~lambda) + theme_bw() + geom_vline(xintercept = 800, colour = &quot;blue&quot;) + geom_hline(yintercept = 0.94, colour = &quot;red&quot;) + annotate(&quot;point&quot;, x = nlm_min$par[&quot;N_init&quot;], y = nlm_min$par[&quot;phiA&quot;], shape = 4, colour = &quot;gold&quot;, size = 5) The gold “x” marks the MLE. From these estimates, we can calculate the MLEs of the population sizes each year, and compare them to the true, simulated values: mleNs &lt;- tibble( year = 0:60, num_adults = N_adults( N0 = nlm_min$par[&quot;N_init&quot;], t = 0:60, lambda = nlm_min$par[&quot;lambda&quot;] ) ) ggplot(mapping = aes(x = year, y = num_adults)) + geom_line(data = sim_vals$N) + geom_point(data = sim_vals$N) + geom_point(data = mleNs, shape = 4, colour = &quot;gold&quot;) The true values are the block circles, the MLEs are the gold x’s. OK, that is not a perfect fit. We could put confidence intervals around those figures, and in the next session with Paul, we will see how to get a standard deviation report out of the TMB result. However, I lean toward the Bayesian side of things. So, we will use our remaining time to show how easy it is to sample from the posterior distribution given a model written in C++ and compiled by TMB. Before we proceed to that, let’s also mention one thing: often when formulating models of this sort, it will be advantageous to transform the variables so that they respect their bounds. For example, given the formulation above, it is entirely possible that the maximum likelihood could be found at a value of \\(\\phi_A &gt; 1\\). So, it is sometimes helpful to parameterize the model differently. We didn’t do that here because it makes it a bit harder to visualize and interpret the likelihood surfaces. 3.6 Sampling from the Posterior with ‘tmbstan’ One very nice feature of using the ‘TMB’ package is that we can plug our compiled TMB object directly into the ‘rstan’ package for doing Bayesian inference by sampling from the posterior distribution implied by the negative log likelihood using No-U-turn MCMC sampling. We do this with the ‘tmbstan’ package, which lets the compiled TMB object interface directory with the ‘rstan’ package. The result is simply awesome! For those who haven’t run across No-U-turn MCMC sampling, it is a special case of Hamiltonian Monte Carlo. This is a type of Monte Carlo sampling that grew out of complex notions from differential geometry. The idea is that one can use the gradient of a posterior surface to design an MCMC sampler that more efficiently samples from that posterior. An outstanding introduction is available on arXiv: Betancourt: A Conceptual Introduction to Hamiltonian Monte Carlo. In order to formulate the model in a Bayesian fashion, we must put priors on the parameters. By default, ‘tmbstan’ just puts uniform priors on the parameters, but, as a consequence, we must specify lower and upper bounds on those parameters. We will do that here, putting natural bounds on the parameters that are naturally bounded (e.g., \\(\\phi_A\\)), leaving the upper end of \\(N_0\\) unbounded (e.g. setting it to Inf), and and putting bounds that are well beyond the support of the data for \\(\\lambda\\). For some reason that I don’t fully understand, we have to remake the TMB AD function before we run the following. Something about having used obj$fn to compute the values of the Neg Log Likelihood, in order to make our contour plots, has gummed things up. But no worries, we just define it again. Here we have all the extra stuff for dealing with the Mac’s issues with linking to things in subdirectories. if(Sys.info()[&quot;sysname&quot;] == &quot;Darwin&quot;) { setwd(&quot;TMB&quot;) dyn.load(dynlib(&#39;hsp_nll&#39;)) obj &lt;- TMB::MakeADFun(data = data, parameters = parameters, DLL=&quot;hsp_nll&quot;) setwd(&quot;..&quot;) } else { dyn.load(dynlib(&quot;TMB/hsp_nll&quot;)) obj &lt;- TMB::MakeADFun(data = data, parameters = parameters, DLL=&quot;hsp_nll&quot;) } Now we can hand that obj object to ‘tmbstan’ to do a short-ish MCMC run. The following code block is set up to detect the number of cores on your computer and then run that many, minus 1, independent instances of the MCMC from different starting values. Doing this is always an important step in assessing MCMC convergence. cores &lt;- parallel::detectCores()-1 options(mc.cores = cores) # simulate random starting values set.seed(1) init.list &lt;- lapply(1:cores, function(x) { c( N_init = runif(1, min = 2000, max = 20000), lambda = runif(1, -0.04, 0.04), phiA = runif(1, 0.75, 0.999) )} ) # run the MCMC fit &lt;- tmbstan( obj, chains=cores, open_progress=FALSE, init=init.list, lower = c(N_init = 0, lambda = -1.0, phiA = 0.0), upper = c(N_init = Inf, lambda = 1.0, phiA = 1.0), iter = 6000, warmup = 2000 ) # print how many cores were used: cores ## [1] 2 After that, printing fit gives a summary of the results: fit ## Inference for Stan model: hsp_nll. ## 2 chains, each with iter=6000; warmup=2000; thin=1; ## post-warmup draws per chain=4000, total post-warmup draws=8000. ## ## mean se_mean sd 2.5% 25% ## N_init 926.08 7.57 359.91 428.95 671.88 ## lambda 0.00 0.00 0.01 -0.03 -0.01 ## phiA 0.92 0.00 0.02 0.89 0.91 ## lp__ -1505.21 0.03 1.26 -1508.49 -1505.77 ## 50% 75% 97.5% n_eff Rhat ## N_init 853.17 1102.41 1805.84 2261 1 ## lambda 0.00 0.01 0.03 2376 1 ## phiA 0.92 0.94 0.96 3063 1 ## lp__ -1504.89 -1504.28 -1503.78 2264 1 ## ## Samples were drawn using NUTS(diag_e) at Wed Nov 2 13:43:36 2022. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). Anyone who has spent time “rolling their own” MCMC sampler will recognize that this was uncharacteristically painless. That is part of the joy of being able to calculate gradients (with the auto-differentiation features of TMB) to use in Hamiltonian Monte Carlo. Also, the maintainers of Stan, TMB, and tmbstan have done an amazing job! If you want a really slick visual representation of the results from the MCMC, you can do: library(shinystan) if(interactive) { launch_shinystan(fit) } That doesn’t get run when rendering this Rmarkown document, because you need to be in a an interactive session for it to run, but, if you are running through this interactively, it will pop up a window to explore the output of the chains that looks like this: That is remarkably easy and slick. I’m impressed. You can also use rstan’s extract() function to get a tibble of all the samples taken: mc_samples &lt;- rstan::extract(fit) %&gt;% as_tibble() mc_samples ## # A tibble: 8,000 × 4 ## N_init lambda phiA lp__ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 993. -0.00263 0.936 -1505. ## 2 694. 0.00944 0.911 -1505. ## 3 979. 0.00459 0.944 -1505. ## 4 762. 0.0135 0.936 -1506. ## 5 638. 0.00770 0.915 -1505. ## 6 823. 0.00244 0.919 -1504. ## 7 885. 0.00518 0.928 -1505. ## 8 1816. -0.0324 0.890 -1507. ## 9 574. 0.00907 0.902 -1506. ## 10 1672. -0.0191 0.927 -1505. ## # … with 7,990 more rows ## # ℹ Use `print(n = ...)` to see more rows You can easily summarise these: mc_samples %&gt;% select(-lp__) %&gt;% mutate(sample_id = 1:n()) %&gt;% pivot_longer(-sample_id) %&gt;% ggplot(aes(x = value)) + geom_histogram(bins = 100) + facet_wrap(~ name, nrow = 3, scales = &quot;free&quot;) And from these samples we could also summarize the variability in the population trajectory by plotting the estimated population sizes at each time point given the sampled values of \\(N_0\\) and \\(\\lambda\\): # calculate the number of adults for each year from each sampled # set of parameters pop_points &lt;- mc_samples %&gt;% mutate( sample_id = 1:n(), .before = N_init ) %&gt;% expand_grid( year = 0:60 ) %&gt;% mutate( num_adults = N_init * exp(lambda * year) ) # plot them ggplot(pop_points, aes(x = year, y = num_adults)) + geom_line(aes(group = sample_id), colour = &quot;gray&quot;, alpha = 0.01) + theme_bw() + geom_point( # add the true, simulated values in there, too data = sim_vals$N, colour = &quot;white&quot;, size = 2 ) + coord_cartesian(ylim = c(0, 4000)) The true, simulated values appear as white points ont he plot above. You could also easily compute the 90% equal-tail credible intervals from those samples: cred_90_ea &lt;- pop_points %&gt;% group_by(year) %&gt;% summarise( lo = quantile(num_adults, 0.05), hi = quantile(num_adults, 0.95), mean = mean(num_adults) ) %&gt;% pivot_longer(-year) ggplot() + geom_line( data = cred_90_ea, mapping = aes(x = year, y = value, linetype = name) ) + geom_point( # add the true, simulated values in there, too data = sim_vals$N, mapping = aes(x = year, y = num_adults), colour = &quot;black&quot; ) The true values appear as black points. 3.7 Summary This has been an exercise in simulating from a simple CKMR inferential model. We hope that doing so has helped solidify your understanding of what these models looks like, and also that the ‘TMB’ and ‘tmbstan’ packages are now a little more familiar, especially to those who have not worked with them much before. References Hillary R, Bravington M, Patterson T et al. (2018) Genetic relatedness reveals total population size of white sharks in eastern australia and new zealand. Scientific reports, 8, 1–9. "],["design-of-ckmr-experiments.html", "Session 4 Design of CKMR Experiments 4.1 White shark design example 4.2 Bearded seal simulation study", " Session 4 Design of CKMR Experiments In this lab, we’ll look at various tools to help design CKMR experiments. We’re relatively liberal with what we call a “design” tool. It could be optimizing sample allocation to achieve maximum precision for a given parameter (e.g., which sexes and ages to target), or it could simply be examining the effect of different types of assumption violations on estimator performance. After all, if a particular type of model is likely to lead to highly biased parameter estimates, it is probably best to adapt model structure, or to leave out certain types of kin comparisons that are likely to violate assumptions. We’ll consider two specific examples: (1) optimizing sample allocation in Hillary et al. (2018) white shark example, and (2) conducting individual-based simulation to investigate impacts of assumption violations in CKMR models for bearded seals. 4.1 White shark design example In a previous lab, we looked at Hillary et al. (2018) model using cross-cohort comparisons of half siblings caught as juveniles. We might look at a few things with this example, such as how we would partition samples across years and ages if we had the ability to do so. Presumably, the optimal allocation would depend on the parameter we were interested in (e.g., population growth (\\(\\lambda\\)), adult survival (\\(S\\)) or terminal year abundance (call this \\(N_T\\)). Both \\(\\lambda\\) and \\(S\\) are parameters of the CKMR model, but \\(N_T\\) is a derived parameter (that is, a function of parameters) and can be computed as \\[\\begin{equation*} N_T = N_0 * \\exp(\\lambda T) \\end{equation*}\\] where \\(T\\) is the number of years in the study. 4.1.1 Fisher information ideas We’ll be using Fisher information ideas to compare anticipated precision associated with various white shark sampling designs. As articulated in the slides on design for this workshop, this involves a number of steps: Allocate potential sample sizes to particular years, ages, sexes, etc. (basically the different covariates one is modeling). These can be expectations (fractions)! Compute sufficient statistics (expected # of comparisons and number of matches for each covariate combination) Treating these as data, calculate second derivatives of the negative log-pseudo-likelihood at the true parameter values Calculate the expected variance-covariance matrix of parameters in the usual way (inverse of the numeric Fisher information matrix) Calculate expected variance of any functions of parameters using the delta method Compare precision (e.g. CV) associated with different designs!! Fortunately, we already have the infrastructure set up to help us the negative log-pseudo-likelihood (both in R and TMB). We could use numerical second derivatives (e.g., using the \\(numDeriv\\) package in R) and not even have to deal with minimizing the NLPL, but Template Model Builder is well set up to produce numerical variance-covariance matrices (including functions of parameters), so why don’t we just follow the path of least resistance and fit our model using TMB. We’ll still need to formulate some alternative designs and what the expected data would look like under each. 4.1.2 Calculating expected data under different design scenarios Let’s set up “true” population dynamics to consist of a stable population with 1000 adults which we assume to be constant over a 20 year period. We’ll set the assume a constant adult survival probability of 0.94, and that sampling occurs over the last 10 years of the time interval. We’ll assume that sampling targets juveniles (ages 3-8) only, so the most we’ll have to go back in time is 8 years (which is why the model needs to go back further in time than just the years that are sampled!!). Ninit = 1000 lambda = 0.0 n_yrs = 20 N = matrix(Ninit,20) phiA = 0.94 ylo=11 yhi=20 ages = c(3:8) #only 3 - 8 yrs olds sampled #&#39; Function to calculate # of expected pairs given true adult abundance, adult #&#39; survival, and # of juvenile white sharks sampled per year (males and female parents modeled together!) #&#39; @param Npy vector of number of sharks to sample each year (num per year) #&#39; @param ages a vector of the ages at which individuals are sampled #&#39; @param age_wts vector of expected proportion of each age in the sample #&#39; @param N Vector of number of adults per year #&#39; @param phiA Adult annual survival probability #&#39; @return This returns two upper triangular matrices `M` and `EC`, both of which have dimension #&#39; (n_yrs x #&#39; n_yrs). The M matrix holds the number of comparisons where the row indexes the #&#39; birth year of the older #&#39; half-sib, and the column gives the birth year of the younger #&#39; half sib. The EC matrix is organized the same way, but holds the expected half-sib count #&#39; (i.e. # of matches) expected_data &lt;- function(Npy,ylo,yhi,ages,age_wts,N,phiA){ age_wts = age_wts/sum(age_wts) #normalize if not n_ages = max(ages)+1 #nb this is just age 0 to the max of sampled age age_prob = rep(0,n_ages) age_prob[ages+1]=age_wts/sum(age_wts) n_yrs = length(Npy) M = EC = matrix(0,n_yrs,n_yrs) # expected number sampled by year and age N_samp = matrix(0,n_yrs,max(ages)+1) #this holds expected number sampled by year and age (w/ age 0) for(iyr in 1:n_yrs){ N_samp[iyr,]=Npy[iyr]*age_prob } # convert to number sampled by birth year N_samp_by = rep(0,n_yrs) for(iyr in 11:n_yrs){ #this would need to be changed to make general - i.e., sampling occurred &lt; year 10 for(iage in 1:n_ages){ N_samp_by[iyr-iage+1]=N_samp_by[iyr-iage+1]+N_samp[iyr,iage] } } #Number of comparisons, probability of matches, expected number of matches for(iyr in 1:(n_yrs-1)){ for(iyr2 in (iyr+1):n_yrs){ M[iyr,iyr2]=N_samp_by[iyr]*N_samp_by[iyr2] age_diff = iyr2-iyr HSP_prob = 4/N[iyr]*(phiA^age_diff) #nb: there&#39;s some duplication here! EC[iyr,iyr2]=M[iyr,iyr2]*HSP_prob } } list(EC=EC,M=M) } Let’s looks at a few scenarios, including (1) sampling ages proportional to their approximate abundance in the population, and (2) sampling ages biased towards younger age classes. We’ll sample 20 individuals per year, as might occur in a balanced monitoring program. We’ll generate an expected number of comparisons and an expected count for each combination of birth years for half-sib comparisons (omitting same-cohort comparisons). Npy = rep(0,20) Npy[11:20] = 20 # sampling proportional to what we&#39;d expect with a constant survival probability of 0.92 age_wts_prop = 0.92^c(0:5) #since &quot;ages&quot; is 3:8, this needs to consist of 6 weights age_wts_young = c(6:1) #6 times more likely to sample &amp; genotype a 3 year old than an 8 year old Exp_data_prop = expected_data(Npy,ylo,yhi,ages,age_wts=age_wts_prop,N,phiA) Exp_data_young = expected_data(Npy,ylo,yhi,ages,age_wts=age_wts_young,N,phiA) One thing we can look at right away is the number of kin pairs for the two designs. For the design with proportional age sampling the number of HSPs is 57.6215; for the design focusing disproportionally on younger ages, we have 57.7955 HSPs. So, very close. 4.1.3 Calculating expected variance under different design scenarios Now let’s fit a “correct” model to these data - that is, one in which all assumptions are met. Note that we don’t actually need to fit a model to do design calculations, but TMB computes variance estimates and delta method approximations for functions of parameters, so we’ll sacrifice a tiny bit of time estimating parameters in order to make our lives easier. If we were going to consider a large number of designs (or to do formal optimization of a design using quadratic programming or something) we’d want to revisit this decision!! So, let’s compile a TMB model, fit a model to data, and look at estimated standard errors of various quantities. # compile TMB negative log pseudo-likeihood function library(TMB) compile(&quot;TMB/hsp_nll2.cpp&quot;) ## [1] 0 # format data and specify starting values for parameters format_data &lt;- function(M,EC){ Indices_gt0 = which(M&gt;0,arr.ind=TRUE) Data = list( n_HSP = EC[Indices_gt0], n_UP = M[Indices_gt0]-EC[Indices_gt0], born_year = Indices_gt0[,2], #for this HSP calc only need birth year of the *younger* animal age_diff = Indices_gt0[,2]-Indices_gt0[,1], present_year= 20 #terminal year for abundance estimate ) Data } Data_prop = format_data(M=Exp_data_prop$M,EC=Exp_data_prop$EC) Data_young = format_data(Exp_data_young$M,Exp_data_young$EC) Parms = list(&quot;N_init&quot; = 1000, &quot;lambda&quot;=1.0, phiA=0.94) dyn.load(dynlib(&quot;TMB/hsp_nll2&quot;)) obj &lt;- TMB::MakeADFun(data = Data_prop, parameters = Parms, DLL=&quot;hsp_nll2&quot;) Opt = nlminb(start=Parms, objective=obj$fn, gradient=obj$gr) ## outer mgc: 698.1 ## Warning in nlminb(start = Parms, objective = obj$fn, ## gradient = obj$gr): NA/NaN function evaluation ## outer mgc: 852.9 ## outer mgc: 376.3 ## outer mgc: 156.6 ## outer mgc: 89.72 ## outer mgc: 4.769 ## outer mgc: 2.079 ## outer mgc: 0.04171 ## outer mgc: 0.03488 ## outer mgc: 0.002186 ## outer mgc: 0.0001492 SD_report_prop=sdreport(obj) ## outer mgc: 0.0001492 ## outer mgc: 0.0005512 ## outer mgc: 0.0008495 ## outer mgc: 8.839 ## outer mgc: 8.957 ## outer mgc: 2.981 ## outer mgc: 2.966 ## outer mgc: 20000 obj &lt;- TMB::MakeADFun(data = Data_young, parameters = Parms, DLL=&quot;hsp_nll2&quot;) Opt = nlminb(start=Parms, objective=obj$fn, gradient=obj$gr) ## outer mgc: 732.1 ## Warning in nlminb(start = Parms, objective = obj$fn, ## gradient = obj$gr): NA/NaN function evaluation ## outer mgc: 762.4 ## outer mgc: 364 ## outer mgc: 140.8 ## outer mgc: 73.41 ## outer mgc: 12.91 ## outer mgc: 24.74 ## outer mgc: 28.85 ## outer mgc: 1.88 ## outer mgc: 0.23 ## outer mgc: 0.01301 ## outer mgc: 0.0005072 SD_report_young=sdreport(obj) ## outer mgc: 0.0005072 ## outer mgc: 0.0002272 ## outer mgc: 0.001242 ## outer mgc: 9.619 ## outer mgc: 9.753 ## outer mgc: 3.035 ## outer mgc: 3.02 ## outer mgc: 20000 # Okay, let’s see what TMB did for us. First let’s check that our estimates are truth - they should be very close since we’re using expected values. print(SD_report_prop$value) ## N_init lambda phiA N_last ## 1.000e+03 -1.864e-08 9.400e-01 1.000e+03 print(SD_report_young$value) ## N_init lambda phiA N_last ## 1.000e+03 -3.057e-08 9.400e-01 1.000e+03 Well that’s reassuring! How about standard errors? print(SD_report_prop$sd) ## [1] 616.47723 0.05528 0.05620 588.11186 print(SD_report_young$sd) ## [1] 667.27825 0.05704 0.05757 570.87206 So there is not much difference in estimator performance when sampling focuses on the youngest juvenile white sharks. Precision on \\(\\lambda\\) and survival is slightly better when we sample the full age range, while precision on terminal year abundance is slightly better when disproportionately focusing on very young white sharks. Although differences weren’t very large here, hopefully you can see how such an analysis might be used to get at “the most bang for your buck” when trying to design a CKMR monitoring program. 4.2 Bearded seal simulation study Next, we’ll return to the biology and approximate sampling scheme for bearded seals (presented as slides in earlier in this workshop). Although bearded seal samples have already been gathered, we could look at a number of different features of data collection that could be relevant for future monitoring. Some ideas include: What type of precision can we expect on adult abundance? How does our current approach of treating age as known tend to affect estimates? Are we likely to be over- or under-estimating abundance or survival with this strategy? Overstating precision? If this is a large issue, we might want to institute procedures for better quantifying aging error (such as collecting two teeth, having them both read, and fitting aging error models to the data) What is the effect of employing fecundity-at-age schedules that overrepresent young animals? For instance, even though age 6 male bearded seals are sexually mature, what if they are not as reproductively successful as older seals? What seal covariates (e.g., age, sex) should be prioritized for genotyping if we’re to maximize precision in abundance estimates going forward? Our time in this workshop is limited, however, so let’s just address the first of these for this lab (what kind of standard error can we expect?). 4.2.1 Setting up simulations: Population dynamics We’re going to use the R package CKMRpop to simulate some virtual bearded seal data, and fit an age structured CKMR model to these data. Given that it’s an age structured model, we’ll need to be careful that the simulation and estimation models are set up similarly - in particular we’ll want to make sure we get pre- and post-breeding census details correct. In fact, many published studies in the ecological literature have erred at this stage! (Kendall et al. (2019)). For bearded seals, pupping occurs from April-June on ice floes; harvests occur year round, but are primarily concentrated in the spring and summer. For this reason, we’ll use a “post-breeding census” where abundance is counted after reproduction has occurred. Pictorally, this looks like The part that people mess up most often is not incorporating survival into the fecundity term. We’ll include 40 ages (0-39) in our model, as the probability of a bearded seal surviving past that point is really small (I believe the oldest known age is in the 30s). Speaking of which, we’ll need to use some values of age-specific survival (\\(\\phi_a\\)) and female fecundity-at-age (\\(f_a\\)) to parameterize our simulation model. We’ll also need some information on male reproduction to determine who successfully mates or not. We’ll use data on male sexual maturity-at-age (call this \\(m_a\\)). We’ve developed a bearded seal survival schedule based on hierarchical meta-analysis of phocid natural mortality (Trukhanova et al. (2018)), and \\(f_a\\) and \\(m_a\\) schedules based on examination of gonadal inspections of harvested seals conducted by ADF&amp;G and reported in Russian literature. Here are some plots of these values. Let’s use these survival and fecundity values to parameterize a Leslie matrix model. Maturity = read.csv(&quot;./csv/Maturity.csv&quot;) Survival = read.csv(&quot;./csv/Survival_ests.csv&quot;) Reprod = read.csv(&quot;./csv/Reproduction_table.csv&quot;) Male_mat &lt;- rep(1,40) Fem_fec &lt;- rep(0.938,40) Male_mat[1:10]=c(0,Maturity$Bearded.male) Fem_fec[1:10]=c(0,Reprod$bearded) A = matrix(0,40,40) for(iage in 1:39){ A[iage+1,iage]=Survival[iage,&quot;bearded&quot;] #assume post-breeding census } #reproduction; nb: adults have to survive to next spring to reproduce # nb: Leslie matrices are &quot;female only&quot; and assume a 50/50 sex ratio at birth A[1,]=0.5*Fem_fec*Survival$bearded There’s a bit of a hiccup, however, since the population growth rate implied by this matrix (as determined by the dominant eigenvalue) is . Given that we’re going to need to perform simulation over 100 years (usually we have to go back two generations to get kinship relationships right), this would have the effect of inducing a 5400+0i percent increase in abundance over the simulation period!! This is clearly not desirable. It’s also an indication that there is probably something a bit off with our Leslie matrix, but it’s not clear where the bias might be. It could have to do with reproductively mature females not always producing a pup every year (\\(f_a\\) biased high), or with survival being overestimated. For the purposes of this simulation, though, we’ll lower survival by multiplying by a fixed constant until \\(\\lambda \\approx 1.0\\). Let’s write a quick function to figure out what this constant should be. leslie_obj &lt;- function(const,Survival,Fem_fec){ A = matrix(0,40,40) for(iage in 1:39){ A[iage+1,iage]=const*Survival[iage,&quot;bearded&quot;] #assume post-breeding census } A[1,]=0.5*Fem_fec*Survival$bearded*const lambda = eigen(A)$values[1] obj=(lambda-1.0)^2 obj } opt = nlminb(0.9,leslie_obj,Survival=Survival,Fem_fec=Fem_fec) print(opt$par,digits=4) ## [1] 0.9607 We’ve got it! Okay, we’ll multiply our current survival schedule by when we conduct our simulations - there will be some demographic stochasticity in any individual-based simulation, but given the large population size abundance should stay pretty much constant. 4.2.2 Setting up simulations: CKMRpop Our next step will be to use the R package CKMRpop to simulate population dynamics. If you were using the ‘CKMRpop’ package on your own, you would need to install it first like this: remotes::install_github(&quot;eriqande/CKMRpop&quot;) However, it has already been installed for the tws-ckmr-2022 RStudio project by the ‘renv’ package, so if you are working in the tws-ckmr-2022 you do not have to do the above. However, after installing it, you will have to download the compiled spip binary which is the underlying simulation engine. That is done with the install_spip() function from the ‘CKMRpop’ as shown below: library(CKMRpop) library(dplyr) if(!spip_exists()) {install_spip(Dir = system.file(package = &quot;CKMRpop&quot;))} Now, let’s set up simulations with our bearded seal life history values. Note the quotation list structure is required by CKMRpop, and that the package is set up to work with a post-breeding census (good for us!). For definitions of the pars list, please use spip_help() or spip_help_full(). pars &lt;- list() pars$`max-age` &lt;- 40 #high survival so need to run for quite a while to kill everyone off pars$`fem-surv-probs` &lt;- pars$`male-surv-probs` &lt;- Survival$bearded*opt$par pars$`fem-prob-repro` &lt;- Fem_fec #probability of reproduction * pars$`repro-inhib` &lt;- 0 #this would allow us to specify e.g. that females couldn&#39;t have pups 2 years in a row (we don&#39;t have that issue!) pars$`male-prob-repro` &lt;- Male_mat pars$`fem-asrf` &lt;- rep(1,40) #if they reproduce, they will have at most 1 offspring pars$`male-asrp` &lt;- rep(1,40) #each reproductively mature male has same expected repro output pars$`offsp-dsn` &lt;- &quot;binary&quot; #override default neg. binomial dist. for litter size pars$`sex-ratio` &lt;- 0.5 Now we’ll set up some initial conditions and specify the length of the simulations. We’ll base the age structure of founders on stable age proportions computed using Leslie matrices, as calculated via the leslie_from_spip functionality in CKMRpop: pars$`number-of-years` &lt;- 120 # we need to specify initial cohort size instead of pop size; let&#39;s set it by assuming # a population size to be 400,000 and by using stable age proportions to figure out what # percentage will be pups N_init = 400000 Age_props = eigen(A)$vectors[,1]/sum(eigen(A)$vectors[,1]) cohort_size &lt;- as.numeric(round(N_init*Age_props[1])) # There&#39;s also some Leslie matrix functionality in spip we could use to set initial age strcutrue L &lt;- leslie_from_spip(pars, cohort_size) pars$`initial-males` &lt;- floor(L$stable_age_distro_fem) pars$`initial-females` &lt;- floor(L$stable_age_distro_male) pars$`cohort-size` &lt;- &quot;const 68737&quot; Note that when the cohort size argument is set to a constant, that the implied fecundity values in the Leslie matrix are rescaled so that the finite population growth rate, \\(\\lambda\\), is 1.0. This can be useful for simulation, but may make comparing fecundity values estimated by a CKMR model to those used to simulate the data difficult (although fecundity-at-age curves should be proportional). If this feature isn’t desired, CKMRpop can also be run with time-specific cohort sizes, or fishsim can be used for simulation. Next, we need to specify how the population is sampled. We’ll assume 20 years of sampling, which are preceded by 100 years of simulations time. This way we will likely capture the oldest possible grandparent-grandchild relationships (e.g., an individual who is age 35 at year 101 having a parent born in year 35 and a grandparent born in year 1). To be really careful we might have three generations time prior to sampling, but given that parents can’t reproduce until age 4 or 5, and that the chances of surviving to old age are very low, we should be fine. samp_start_year &lt;- 101 samp_stop_year &lt;- 120 pars$`discard-all` &lt;- 0 pars$`gtyp-ppn-fem-post` &lt;- paste( samp_start_year, &quot;-&quot;, samp_stop_year, &quot; &quot;, paste(rep(0.00025, pars$`max-age`), collapse = &quot; &quot;), sep = &quot;&quot; ) #basically we&#39;re saying that hunters aren&#39;t biased towards a particular age class, and that we&#39;re sampling 0.025% of the pop per year - about 100/year pars$`gtyp-ppn-male-post` &lt;- pars$`gtyp-ppn-fem-post` Okay, now that things are set up, we can run a CKMRpop simulation! This is super easy, although it takes a few minutes since we’re talking about simulating a populations size of 400,000 of 120 years and recording the geneaology along the way. I’m actually super impressed that this is so fast! I’ve put in an option for Rmarkdown to “cache” the results of this operation so that it doesn’t have to do it when this is compiled. So, just beware if you’re trying to run it on your own computer!! set.seed(2020) # inauspicious year as a seed for reproducibility of results spip_dir &lt;- run_spip(pars = pars) # run spip ## Running spip in directory /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpgOCSlV/file2c332338df03 ## Done running spip. Output file size is 1130.219259 Mb ## Processing output file with awk ## Done processing output into spip_pedigree.tsv, spip_prekill_census.tsv, and spip_samples.tsv slurped &lt;- slurp_spip(spip_dir, 2) # read the spip output into R ## Rows: 1627 Columns: 3 ## ── Column specification ─────────────────────────────── ## Delimiter: &quot;\\t&quot; ## chr (2): X1, X2 ## lgl (1): X3 ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ggplot_census_by_year_age_sex(slurped$census_postkill) The above plot shows the age and sex composition, as well as the total size of the population over time. For a design study the next thing we want to do is to start looking at sampled animals and number of kin pairs to make sure they line up with what we were hoping. nrow(slurped$samples) ## [1] 1627 crel &lt;- compile_related_pairs(slurped$samples) So, after 20 years of sampling (at an average of 81.35 samples per year), we end up with 1627 tissue samples. Assuming none are corrupted (a dubious assumption), they can be genetically analyzed and kin relationships can be determined. CKMRpop actually keeps track of a lot of relationships - more than are needed for CKMR analysis (at least in CKMR’s current state). Nevertheless, they can be useful because they can allow us to examine the performance of CKMR estimators when there are errors in kin determination (e.g., grandparent-grandchild or aunt-niece being mistaken for half-sibs). Here is a summary of true kin-pairs in our sample: relat_counts &lt;- count_and_plot_ancestry_matrices(crel) relat_counts$highly_summarised ## # A tibble: 5 × 3 ## dom_relat max_hit n ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 FC 1 54 ## 2 A 1 30 ## 3 Si 1 12 ## 4 GP 1 4 ## 5 PO 1 4 Note that there are 54 half-cousins (FC), 30 half-niblings (aunt-niece, uncle-niece, etc.), 12 half-siblings, 4 grandparent-grandchild, and 4 parent-offspring pairs. Note that the “max_hit” column indicates that number of shared ancestors at the level of the dominant relationship; so a “2” in this column would indicate a full sibling, full aunt-niece, etc. Since the maximum value if 1 here, this indicates they are all half-sibling, half-aunt-niece, etc. Which is good, since presence of full niblings/thiatics would confound HSP inference. There are some additional graphical tools in CKMRpop to examine pairwise relationships (see the plot_conn_comps() function, or investigate the “plots” objects in the relat_counts object), but we won’t do that in this manual (free feel to do so yourself though!). What else may we deduce at this point? First, with only 4 POPs and 12 HSPs, we’re considerably below the “rule of thumb” of 50 kin pairs for reliable CKMR inference. These numbers may change slightly if we were to repeat the simulation, but the total number will be in the same ballpark. Second, we do get a substantial amount of GGPs, so we’ll need to accommodate these somehow, either by modeling or by restricting the time-of-death and age-ranges of HSP comparisons to make sure that GGPs are not included in HSP comparisons. We’re in the unique position of actually having conducted kin finding on \\(\\approx 1500\\) real bearded seal samples, so it is instructive to compare results of simulations to real data. When we analyzed real bearded seal data, we found 2 POPs, and depending on where we put the PLOD threshold, we arrived at 17-25 HSPs + GGPs. However, this number may have been inflated by a larger-than-expected number of PHSPs (arising, perhaps, from heterogeneity in male reproductive success). So simulations largely gave numbers very similar when we went and applied CKMR in practice, which is encouraging! 4.2.3 Formatting data for estimation Now that we’ve simulated some data, we need to put them into a form that we can analyze. For our bearded seal paper, I programmed a log pseudo-likelihood in TMB (see bearded_nll.cpp in the TMB directory of this project), and we will use that for estimation here. This version does not include the capacity for modeling GGPs, so let’s ignore that added complication for now (the final analysis does, but calculations are quite complex). For both POPs and HSPs, we need to summarize sufficient statistics for the number of comparisons and number of matches. A typical way to do this is by grouping according to relevant covariates. For POPs this includes birth dates of the two animals being compared, as well as the death date of the older animal (because the older animal can’t be a parent if it dies before the younger animal is conceived (for a poential male parent) or before the younger animal is weaned (for a potential female parent). We’ll thus summarize POP comparisons and matches using three-dimensional arrays, which facilitate easy looping when calculating pseudolikelihood. We’ll also do maternal and paternal POPs separately. For HSPs, death dates are unneeded; all we need is the birth dates for prospective HSPs. Looking at male and female fecundity-at-age vectors, it looks like we should probably limit comparisons to animals that are born within \\(approx 6 years\\) of each other to preclude the possibility that an apparent HSP is actually a GGP. We’ll lose two HSPs in the process, but such is life! # here, &#39;bi&#39;, &#39;di&#39;, and &#39;bj&#39; index birth of the older animal, death of the older animal, and birth of the younger animal # as far as dimensions, there are 20 years of data, but birth dates can be earlier (up one generation time) n_comp_PPO_bidibj=n_comp_MPO_bidibj=n_match_PPO_bidibj=n_match_MPO_bidibj=array(0,dim=c(60,20,60)) # HSPs are indexed by bi, bj - the birth times of the older and younger animal; note that # the number of comparisons does not depend on the sex of the unobserved parent, but matches are sex-specific n_comp_HS_bibj = n_match_PHS_bibj= n_match_MHS_bibj= matrix(0,60,60) # POP matches PO_only &lt;- crel %&gt;% filter(dom_relat == &quot;PO&quot;) for(i in 1:nrow(PO_only)){ FIRST = (PO_only$born_year_1[i] &lt; PO_only$born_year_2[i]) # case 1: parent is animal 1 if(FIRST){ p_by = PO_only$born_year_1[i]-60 p_sex = (PO_only$sex_1[i]==&quot;M&quot;)+1 #1 for female, 2 for males p_dy = PO_only$samp_years_list_1[[i]]-100 o_by = PO_only$born_year_2[i] - 60 #year 81 in simulation = year 1 for CKMR inference } else{ p_by = PO_only$born_year_2[i]-60 p_sex = (PO_only$sex_2[i]==&quot;M&quot;)+1 #1 for female, 2 for males p_dy = PO_only$samp_years_list_2[[i]]-100 o_by = PO_only$born_year_1[i] - 60 #year 81 in simulation = year 1 for CKMR inference } if(p_sex==1)n_match_MPO_bidibj[p_by,p_dy,o_by]=n_match_MPO_bidibj[p_by,p_dy,o_by]+1 else n_match_PPO_bidibj[p_by,p_dy,o_by]=n_match_PPO_bidibj[p_by,p_dy,o_by]+1 } # HSP matches HS_only &lt;- crel %&gt;% filter(dom_relat == &quot;Si&quot;) for(i in 1:nrow(HS_only)){ FIRST = (HS_only$born_year_1[i] &lt; HS_only$born_year_2[i]) lt7 = (abs(HS_only$born_year_1[i] - HS_only$born_year_2[i])&lt;7) # case 1: parent is animal 1 if(lt7){ if(FIRST){ by1 = HS_only$born_year_1[i] - 60 by2 = HS_only$born_year_2[i] - 60 #year 81 in simulation = year 1 for CKMR inference } else{ by1 = HS_only$born_year_2[i] - 60 by2 = HS_only$born_year_1[i] - 60 #year 81 in simulation = year 1 for CKMR inference } #to determine sex of parent, we need to access ancestry vectors and pull off an &quot;M&quot; for male or &quot;F&quot; for female parent_ID = HS_only$ancestors_1[i][[1]][unlist(HS_only$primary_shared_ancestors[i])[1]] sex = substr(parent_ID,1,1) if(sex==&quot;F&quot;)n_match_MHS_bibj[by1,by2]=n_match_MHS_bibj[by1,by2]+1 else n_match_PHS_bibj[by1,by2]=n_match_PHS_bibj[by1,by2]+1 } } #Comparisons n_indiv = nrow(slurped$samples) for(i1 in 1:(n_indiv-1)){ for(i2 in (i1+1):n_indiv){ born_diff = slurped$samples$born_year[i1] - slurped$samples$born_year[i2] if(abs(born_diff)&lt;7){ if(born_diff&lt;0){ #first animal is older p_by = slurped$samples$born_year[i1]-60 p_dy = slurped$samples$samp_years_list[i1][[1]]-100 p_sex = (slurped$samples$sex[i1]==&quot;M&quot;)+1 #1 for female, 2 for males o_by = slurped$samples$born_year[i2] - 60 #year 81 in simulation = year 1 for CKMR } else{ if(born_diff&gt;0){ #note no comparisons for animals born in same year p_by = slurped$samples$born_year[i2]-60 p_dy = slurped$samples$samp_years_list[i2][[1]]-100 p_sex = (slurped$samples$sex[i2]==&quot;M&quot;)+1 #1 for female, 2 for males o_by = slurped$samples$born_year[i1] - 60 #year 81 in simulation = year 1 for CKMR } } if(p_sex==1)n_comp_MPO_bidibj[p_by,p_dy,o_by] = n_comp_MPO_bidibj[p_by,p_dy,o_by] + 1 else n_comp_PPO_bidibj[p_by,p_dy,o_by] = n_comp_PPO_bidibj[p_by,p_dy,o_by] + 1 n_comp_HS_bibj[p_by,o_by]=n_comp_HS_bibj[p_by,o_by]+1 } } } 4.2.4 Fitting the CKMR model Okay, now we have our data formatted and it’s time to load up the jnll function from TMB, and pass data and initial parameter values to it to enable parameter estimation. Note that we’re going to pass fecundity schedules as known constants, and will handle survival by passing informative prior distributions into the estimation routine (it is a 3-parameter reduced-additive-Weibull model). Owing to low sample sizes, we’re also going to enforce a constraint of a constant population size. Here is some code to setup and run the model: Data=list(&quot;n_yrs&quot;=60,&quot;n_yrs_data&quot;=20,&quot;n_seals&quot;=nrow(slurped$samples),&quot;n_ages&quot;=40,&quot;Male_mat&quot;=Male_mat,&quot;Fem_fec&quot;=Fem_fec,&quot;A&quot;=A, &quot;n_match_PHS_bibj&quot;=n_match_PHS_bibj,&quot;n_match_MHS_bibj&quot;=n_match_MHS_bibj,&quot;n_comp_HS_bibj&quot;=n_comp_HS_bibj,&quot;n_match_MPO_bidibj&quot;=n_match_MPO_bidibj,&quot;n_comp_MPO_bidibj&quot;=n_comp_MPO_bidibj,&quot;n_match_PPO_bidibj&quot;=n_match_PPO_bidibj,&quot;n_comp_PPO_bidibj&quot;=n_comp_PPO_bidibj,mu_log_eta1=log(0.055),mu_log_eta2=log(2.8),mu_log_eta3=log(0.076),sd_log_eta1=0.07*abs(log(0.055)),sd_log_eta2=0.2*abs(log(2.8)),sd_log_eta3=abs(0.08*log(0.076)),lambda_expect=1.0) #SD log multipliers set to achieve approx CV of 0.2 on real scale Params = list(&quot;n0_log&quot;=log(20000),&quot;log_eta1&quot;=log(0.055),&quot;log_eta2&quot;=log(2.80),&quot;log_eta3&quot;=log(0.076)) #intial param values Map = list() #specify fixed parameter values #Random= c(&quot;log_eta1&quot;,&quot;log_eta2&quot;,&quot;log_eta3&quot;) Random=NULL library(TMB) getwd() ## [1] &quot;/Users/runner/work/tws-ckmr-2022/tws-ckmr-2022&quot; TmbFile = &quot;./TMB/bearded_nll.cpp&quot; compile(TmbFile ) ## [1] 0 TmbExec=&quot;./TMB/bearded_nll&quot; dyn.load(dynlib(TmbExec)) Obj &lt;- MakeADFun(data=Data, parameters=Params, random=Random, map=Map, hessian=FALSE, DLL=&quot;bearded_nll&quot;) Obj$fn( Obj$par ) ## [1] 2176425 Report = Obj$report() init_report = Report #Minimize negative log likelihood and time it Start_time = Sys.time() Opt = nlminb(start=Params, objective=Obj$fn, gradient=Obj$gr) ## outer mgc: 20936170 ## outer mgc: 8511535 ## outer mgc: 1708844 ## outer mgc: 1296351 ## outer mgc: 846387 ## outer mgc: 38796 ## outer mgc: 17648 ## outer mgc: 354.1 ## outer mgc: 2343 ## outer mgc: 180.7 ## outer mgc: 1431 ## outer mgc: 2875 ## outer mgc: 1552 ## outer mgc: 1150 ## outer mgc: 45.01 ## outer mgc: 180.9 ## outer mgc: 488.8 ## outer mgc: 123.3 ## outer mgc: 12.81 ## outer mgc: 4.869 ## outer mgc: 0.3811 ## outer mgc: 3.208 ## outer mgc: 8.661 ## outer mgc: 5.924 ## outer mgc: 45.47 ## outer mgc: 7.402 ## outer mgc: 1.951 ## outer mgc: 3.413 ## outer mgc: 3.515 ## outer mgc: 2.067 ## outer mgc: 0.2946 ## outer mgc: 0.02022 End_time = Sys.time() Report=Obj$report() SD_report=sdreport(Obj) ## outer mgc: 0.02022 ## outer mgc: 0.06032 ## outer mgc: 0.0199 ## outer mgc: 63308 ## outer mgc: 63004 ## outer mgc: 1107 ## outer mgc: 1110 ## outer mgc: 50079 ## outer mgc: 50038 ## outer mgc: 1406518 N_est_TMB = SD_report$value[which(names(SD_report$value)==&quot;N&quot;)] #check for convergence Opt$message ## [1] &quot;relative convergence (4)&quot; Okay, so it looks like our model converged, so it’s time to check on results. It looks like we’re estimating abundance as 2.7104^{5} with a standard error of 7.256^{4} - so the CV is 0.2677. That’s not bad! But, remember we’ve employed a large number of assumptions (constant abundance, etc.) to get an estimate with such low sample sizes. Our estimate (270,000) is lower than true abundance (400,000) but if we constructed a confidence interval it would include the true value, so it’s not something to be worried about. If we wanted to quantify estimator performance in a more rigorous way, we’d want to conduct a large number of simulations and look at things like bias, confidence interval coverage, etc. How about survival? Recall that CKMR can inform estimation of adult survival, which is why we used a prior on the three parameter survival-at-age function. Presumably the prior specifies all the information on juvenile and subadult survival, but the HSP data provide additional information on adult survival. There’s actually another hidden piece of information, and that is the constraint that population size is constant (basically a \\(\\lambda=1.0\\) constraint). So when we compare the prior survival model to the posterior survival model we see quite a shift - but a lot of that has to do with \\(\\lambda=1.0\\). Plot_df = data.frame(&quot;Type&quot;=rep(c(&quot;Prior&quot;,&quot;CKMR&quot;),each=40), &quot;Value&quot;=c(Survival$bearded,Report$S_a), &quot;Age&quot;= rep(c(0:39),2)) library(ggplot2) ggplot(Plot_df)+geom_line(aes(x=Age,y=Value,colour=Type),size=1.1)+theme(text=element_text(size=16)) 4.2.5 Thought experiment What else about the bearded seal example would make sense to examine using simulation?? References Hillary R, Bravington M, Patterson T et al. (2018) Genetic relatedness reveals total population size of white sharks in eastern australia and new zealand. Scientific reports, 8, 1–9. Kendall BE, Fujiwara M, Diaz-Lopez J et al. (2019) Persistent problems in the construction of matrix population models. Ecological modelling, 406, 33–43. Trukhanova IS, Conn PB, Boveng PL (2018) Taxonomy-based hierarchical analysis of natural mortality: Polar and subpolar phocid seals. Ecology and evolution, 8, 10530–10541. "],["references.html", "References", " References Fay FH, Rausch VR, Feltz ET (1967) Cytogenetic comparison of some pinnipeds (mammalia: eutheria). Canadian Journal of Zoology, 45, 773–778. Hillary R, Bravington M, Patterson T et al. (2018) Genetic relatedness reveals total population size of white sharks in eastern australia and new zealand. Scientific reports, 8, 1–9. Kendall BE, Fujiwara M, Diaz-Lopez J et al. (2019) Persistent problems in the construction of matrix population models. Ecological modelling, 406, 33–43. Trukhanova IS, Conn PB, Boveng PL (2018) Taxonomy-based hierarchical analysis of natural mortality: Polar and subpolar phocid seals. Ecology and evolution, 8, 10530–10541. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
